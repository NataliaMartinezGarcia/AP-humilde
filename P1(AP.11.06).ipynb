{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4afa75b-461a-42cf-b630-91d1fd9c17bc",
   "metadata": {
    "id": "f4afa75b-461a-42cf-b630-91d1fd9c17bc"
   },
   "source": [
    "# Práctica 1 - NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d73a6-219e-4cfc-b5f9-449bb33c4d70",
   "metadata": {
    "id": "1b8d73a6-219e-4cfc-b5f9-449bb33c4d70"
   },
   "source": [
    "### Natalia Martínez García, Lucía Vega Navarrete\n",
    "### Grupo: AP.11.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "E_VBMNQGp4Ma",
   "metadata": {
    "id": "E_VBMNQGp4Ma"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras import layers, models, regularizers, metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f01e6-92b7-47fb-98df-31f7954127bb",
   "metadata": {
    "id": "868f01e6-92b7-47fb-98df-31f7954127bb"
   },
   "source": [
    "En esta práctica usamos el dataset STL-10, que contiene imágenes de 96×96 en color y 10 clases (avión, pájaro, coche, gato, ciervo, perro, caballo, mono, barco, camión). El objetivo es entrenar una red neuronal totalmente conectada para clasificar estas imágenes.\n",
    "Primero cargamos y preprocesamos los datos: normalizamos las imágenes, convertimos las etiquetas a one-hot y aplanamos cada imagen en un vector. Después entrenamos varios modelos cambiando la regularización para intentar mejorar la generalización y evitar sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042e924-928e-41c1-b1a8-c7ebfdd9f46a",
   "metadata": {
    "id": "0042e924-928e-41c1-b1a8-c7ebfdd9f46a"
   },
   "source": [
    "### 1. Carga del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdCgH9LAnJrY",
   "metadata": {
    "id": "bdCgH9LAnJrY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "INFORMACIÓN DEL DATASET\n",
      "==================================================\n",
      "NOMBRE: stl10\n",
      "\n",
      "IMÁGENES:\n",
      " - Dimensiones: (96, 96, 3)\n",
      " - Tipo: <class 'numpy.uint8'>\n",
      " - Longitud aplanada: 27648\n",
      "\n",
      "ETIQUETAS:\n",
      " - Número de clases: 10\n",
      " - Clases: airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck\n",
      "\n",
      "SPLITS:\n",
      " - Train: 5,000 imágenes\n",
      " - Test: 8,000 imágenes\n",
      " - Unlabelled: 100,000 imágenes (NO LOS USAMOS)\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el dataset STL-10 ya dividido en entrenamiento y test.\n",
    "# as_supervised=True hace que cada elemento tenga forma (imagen, etiqueta)\n",
    "# with_info=True también devuelve info extra del dataset (número de clases, tamaño de imagen, etc.)\n",
    "\n",
    "(train, test), info_ds = tfds.load(\n",
    "    'stl10',\n",
    "    split=['train', 'test'],\n",
    "    # shuffle_files=True, # PARA QUE VENGAN DESORDENADOS\n",
    "    as_supervised=True,  # Devuelve tuplas (imagen, etiqueta)\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "num_clases = info_ds.features['label'].num_classes\n",
    "nombres_clases = info_ds.features['label'].names\n",
    "tamano_imagen = info_ds.features['image'].shape\n",
    "dimension_entrada = np.prod(tamano_imagen)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"INFORMACIÓN DEL DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"NOMBRE: {info_ds.name}\")\n",
    "print(f\"\\nIMÁGENES:\")\n",
    "print(f\" - Dimensiones: {tamano_imagen}\")\n",
    "print(f\" - Tipo: {info_ds.features['image'].numpy_dtype}\")\n",
    "print(f\" - Longitud aplanada: {dimension_entrada}\")\n",
    "\n",
    "\n",
    "print(f\"\\nETIQUETAS:\")\n",
    "print(f\" - Número de clases: {num_clases}\")\n",
    "print(f\" - Clases: {', '.join(nombres_clases)}\")\n",
    "\n",
    "print(f\"\\nSPLITS:\")\n",
    "print(f\" - Train: {info_ds.splits['train'].num_examples:,} imágenes\")\n",
    "print(f\" - Test: {info_ds.splits['test'].num_examples:,} imágenes\")\n",
    "print(f\" - Unlabelled: {info_ds.splits['unlabelled'].num_examples:,} imágenes (NO LOS USAMOS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e161b9-f477-45db-b7f8-018919714037",
   "metadata": {
    "id": "e0e161b9-f477-45db-b7f8-018919714037"
   },
   "source": [
    "### 2. Preprocesado del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "As9QMqozkccY",
   "metadata": {
    "id": "As9QMqozkccY"
   },
   "outputs": [],
   "source": [
    "def preprocesado(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32) / 255.0  # imagen a float32 y escala [0,1]\n",
    "    imagen = tf.reshape(imagen, [-1]) # aplanamos\n",
    "    etiqueta = tf.one_hot(etiqueta, depth = num_clases) # one-hot\n",
    "    return imagen, etiqueta\n",
    "\n",
    "def preprocesado_dataset(dataset):\n",
    "    imagenes = []\n",
    "    etiquetas = []\n",
    "\n",
    "    for img, label in dataset:\n",
    "        imagen, etiqueta = preprocesado(img, label)\n",
    "        imagenes.append(imagen)\n",
    "        etiquetas.append(etiqueta)\n",
    "\n",
    "    return np.array(imagenes), np.array(etiquetas)\n",
    "\n",
    "train_inputs, train_targets = preprocesado_dataset(train)\n",
    "test_inputs, test_targets = preprocesado_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df73e70",
   "metadata": {
    "id": "3df73e70"
   },
   "source": [
    "Las imágenes vienen en formato uint8 (enteros sin signo), con valores de píxeles  entre 0 y 255. Escalamos los píxeles al rango [0, 1] dividiendo por 255 para que la red converja más rápido y de forma más estable.\n",
    "\n",
    "Además, las imágenes son matrices de 96×96×3 (alto, ancho, canales RGB), pero una red neuronal densa solo puede trabajar con vectores 1D. Por eso necesitamos aplanar la imagen: el resultado es un vector de longitud 27648. Con esto la red no conoce que un píxel está al lado del otro (pierde la información espacial).\n",
    "\n",
    "Usamos one-hot encoding cuando tenemos variables categóricas que no tiene sentido ordenar (no hay una categoría “mayor” o “menor” que la otra), como es nuestro caso con las 10 clases del dataset (avión, pájaro, coche, gato, etc.). Con esto convertimos una etiqueta categórica en un vector donde solo la posición correspondiente a esa categoría tiene un 1 y el resto son 0s (por ejemplo, la clase 0 se convierte en [1,0,0,0,0,0,0,0,0,0]). Si dejáramos las etiquetas como números del 0 al 9, podría interpretarse erróneamente que existe una relación de orden entre ellas. AÑADIR ALGO DEL CROSSENTROPY ?? LUEGO CUANDO LO ENTENDAMOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wcojleQKoccO",
   "metadata": {
    "id": "wcojleQKoccO"
   },
   "outputs": [],
   "source": [
    "# SEPARAR PARTE DE TRAINING PARA VALIDATION\n",
    "\n",
    "indices_permutation = np.random.permutation(len(train_inputs))\n",
    "shuffled_inputs = train_inputs[indices_permutation]\n",
    "shuffled_targets = train_targets[indices_permutation]\n",
    "\n",
    "num_validation_samples = int(0.2 * len(train_inputs))\n",
    "val_inputs = shuffled_inputs[:num_validation_samples]\n",
    "val_targets = shuffled_targets[:num_validation_samples]\n",
    "training_inputs = shuffled_inputs[num_validation_samples:]\n",
    "training_targets = shuffled_targets[num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39393f45",
   "metadata": {
    "id": "39393f45"
   },
   "source": [
    "Para la división del dataset, se mezclan las muestras del conjunto de entrenamiento, de manera que la separación entre entrenamiento y validación sea aleatoria.  \n",
    "\n",
    "Luego, del conjunto de entrenamiento ya barajado, se toma un 20 % de las muestras para formar el conjunto de validación, mientras que el 80 % restante se mantiene como conjunto de entrenamiento. Este porcentaje es el más habitual en aprendizaje automático, ya que permite evaluar correctamente el modelo sin reducir demasiado la cantidad de datos disponibles para entrenar. El conjunto de validación no participa en el aprendizaje del modelo, sino que se usa durante el entrenamiento para comprobar su progreso y detectar posibles casos de sobreajuste, asegurando que el modelo generalice bien a datos nuevos.\n",
    "\n",
    "El conjunto de test, por su parte, ya viene definido por defecto en el dataset STL-10, separado del entrenamiento. Este conjunto no se modifica ni se utiliza durante el proceso de entrenamiento o validación, y se reserva exclusivamente para evaluar el rendimiento final sobre nuevos datos que no ha visto antes una vez que ya está completamente entrenado.\n",
    "\n",
    "Los datos se agrupan en batches de 32 muestras, es decir, el modelo procesa 32 imágenes por iteración antes de actualizar sus pesos. Elegimos este tamaño porque es lo suficientemente pequeño para que el aprendizaje consuma demasiada memoria, pero lo bastante grande para aprovechar la eficiencia del cálculo en paralelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e9a2ce-6e07-44cf-8452-af7cf07089ae",
   "metadata": {
    "id": "55e9a2ce-6e07-44cf-8452-af7cf07089ae",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. Creación y entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e510386-8e3b-4ec3-ad17-42344cc00564",
   "metadata": {
    "id": "1e510386-8e3b-4ec3-ad17-42344cc00564"
   },
   "source": [
    "Como queremos entrenar varios modelos y guradar sus historiales y métricas, decidimos hacer una función general de entrenamiento para no repetir código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d3bb7-a930-4f3b-a22d-310a9bc6b5bb",
   "metadata": {
    "id": "211d3bb7-a930-4f3b-a22d-310a9bc6b5bb"
   },
   "outputs": [],
   "source": [
    "def entrenar(modelo, train, val, test, epochs=15):\n",
    "    history = modelo.fit(train, validation_data=val, epochs=epochs, verbose=1)\n",
    "\n",
    "    # Evalúa en test: devuelve [loss, accuracy, precision, recall, f1_score]\n",
    "    loss, acc, prec, rec, f1 = modelo.evaluate(test, verbose=0)\n",
    "\n",
    "    # Muestra los resultados de forma ordenada\n",
    "    print(\"\\nResultados en TEST:\")\n",
    "    print(f\"Loss: {loss:.4f}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "    return history, loss, acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab63e3-b229-479b-9135-2f06b4f04a61",
   "metadata": {
    "id": "2aab63e3-b229-479b-9135-2f06b4f04a61",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<p style=\"color:red; font-weight:bold; line-height:1.5;\">\n",
    "- XQ ESE NÚMERO DE EPOCHS. Ns q criterio se sigue lmao<br>\n",
    "- XQ ESAS MÉTRICAS\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d207957-8afa-47be-bc4d-4c54eb3a21a9",
   "metadata": {
    "id": "5d207957-8afa-47be-bc4d-4c54eb3a21a9"
   },
   "source": [
    "<p style=\"color:red; font-weight:bold; line-height:1.5;\">\n",
    "PARA LOS MODELOS: <br>\n",
    "- Explicar cada cosa del compile<br>\n",
    "- El num de neuronas en las capas ocultas y la activación <br>\n",
    "- El dropout <br>\n",
    "- regularizaciones\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a1369-909e-4b58-9e8a-3dbbe4fce487",
   "metadata": {
    "id": "aa7a1369-909e-4b58-9e8a-3dbbe4fce487"
   },
   "source": [
    "#### 3.1) Modelo 1- Vanilla (sin regularización)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb4d07-b2e3-489e-b225-f30fcff9ca30",
   "metadata": {
    "id": "cfdb4d07-b2e3-489e-b225-f30fcff9ca30"
   },
   "outputs": [],
   "source": [
    "# Función que construye el modelo básico\n",
    "def vanilla():\n",
    "    # Creamos un modelo secuencial, las capas se apilan una tras otra\n",
    "    modelo = models.Sequential([\n",
    "        layers.Input(shape=(dimension_entrada,)),  # Capa de entrada con el tamaño del vector aplanado\n",
    "        layers.Dense(512, activation='relu'), # Primera capa oculta con 512 neuronas y activación ReLU\n",
    "        layers.Dense(256, activation='relu'), # Segunda capa oculta con 256 neuronas y activación ReLU\n",
    "        layers.Dense(num_clases, activation='softmax') # Capa de salida con tantas neuronas como clases (10) y activación softmax. softmax devuelve probabilidades para cada clase\n",
    "    ])\n",
    "\n",
    "    # optimizador base: Adam (muy estándar hoy en día)\n",
    "    modelo.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy', # porcentaje total de aciertos\n",
    "            metrics.Precision(name='precision'),# mide falsos positivos\n",
    "            metrics.Recall(name='recall'),  # mide falsos negativos\n",
    "            metrics.F1Score(name='f1_score', average='macro')  # media F1 por clase\n",
    "        ]\n",
    "    )\n",
    "    return modelo\n",
    "\n",
    "modelo_base = vanilla() # Creamos una instancia del modelo base llamando a la función\n",
    "modelo_base.summary() # Mostramos un resumen con el número de capas, parámetros y formas de entrada/salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3de47-48e3-47c2-8a33-9b7270a94db9",
   "metadata": {
    "id": "1eb3de47-48e3-47c2-8a33-9b7270a94db9",
    "outputId": "587ea041-07e8-4f08-c6ae-70aa89f5353a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 99ms/step - accuracy: 0.2050 - f1_score: 0.2044 - loss: 4.6240 - precision: 0.2362 - recall: 0.1110 - val_accuracy: 0.3150 - val_f1_score: 0.2655 - val_loss: 2.0319 - val_precision: 0.5526 - val_recall: 0.1260\n",
      "Epoch 2/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.2735 - f1_score: 0.2705 - loss: 2.1378 - precision: 0.4540 - recall: 0.1210 - val_accuracy: 0.3160 - val_f1_score: 0.2738 - val_loss: 1.8717 - val_precision: 0.5000 - val_recall: 0.1170\n",
      "Epoch 3/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.3142 - f1_score: 0.3118 - loss: 1.9128 - precision: 0.5535 - recall: 0.1138 - val_accuracy: 0.3200 - val_f1_score: 0.2909 - val_loss: 1.9055 - val_precision: 0.6932 - val_recall: 0.1220\n",
      "Epoch 4/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.3128 - f1_score: 0.3096 - loss: 1.8692 - precision: 0.6047 - recall: 0.1170 - val_accuracy: 0.3600 - val_f1_score: 0.3277 - val_loss: 1.7159 - val_precision: 0.6326 - val_recall: 0.1360\n",
      "Epoch 5/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.3363 - f1_score: 0.3309 - loss: 1.7957 - precision: 0.6007 - recall: 0.1335 - val_accuracy: 0.4020 - val_f1_score: 0.3613 - val_loss: 1.6436 - val_precision: 0.7077 - val_recall: 0.1840\n",
      "Epoch 6/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.3630 - f1_score: 0.3542 - loss: 1.7288 - precision: 0.6107 - recall: 0.1373 - val_accuracy: 0.3390 - val_f1_score: 0.3330 - val_loss: 1.7949 - val_precision: 0.5464 - val_recall: 0.1650\n",
      "Epoch 7/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.3795 - f1_score: 0.3746 - loss: 1.6996 - precision: 0.6400 - recall: 0.1657 - val_accuracy: 0.4080 - val_f1_score: 0.3893 - val_loss: 1.6390 - val_precision: 0.6863 - val_recall: 0.1860\n",
      "Epoch 8/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.3750 - f1_score: 0.3690 - loss: 1.6941 - precision: 0.6383 - recall: 0.1650 - val_accuracy: 0.4270 - val_f1_score: 0.3919 - val_loss: 1.6073 - val_precision: 0.6730 - val_recall: 0.2140\n",
      "Epoch 9/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.4000 - f1_score: 0.3947 - loss: 1.6210 - precision: 0.6548 - recall: 0.1877 - val_accuracy: 0.4070 - val_f1_score: 0.3836 - val_loss: 1.7093 - val_precision: 0.6639 - val_recall: 0.1620\n",
      "Epoch 10/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 96ms/step - accuracy: 0.4212 - f1_score: 0.4132 - loss: 1.5900 - precision: 0.6718 - recall: 0.1960 - val_accuracy: 0.4740 - val_f1_score: 0.4745 - val_loss: 1.4395 - val_precision: 0.7893 - val_recall: 0.2060\n",
      "Epoch 11/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 96ms/step - accuracy: 0.4310 - f1_score: 0.4246 - loss: 1.5775 - precision: 0.6715 - recall: 0.2065 - val_accuracy: 0.4580 - val_f1_score: 0.4172 - val_loss: 1.5142 - val_precision: 0.7944 - val_recall: 0.2550\n",
      "Epoch 12/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.4333 - f1_score: 0.4288 - loss: 1.5310 - precision: 0.6956 - recall: 0.2285 - val_accuracy: 0.4110 - val_f1_score: 0.3817 - val_loss: 1.5674 - val_precision: 0.5829 - val_recall: 0.2250\n",
      "Epoch 13/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.4588 - f1_score: 0.4536 - loss: 1.4668 - precision: 0.6995 - recall: 0.2555 - val_accuracy: 0.5050 - val_f1_score: 0.4827 - val_loss: 1.3506 - val_precision: 0.7558 - val_recall: 0.2940\n",
      "Epoch 14/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.4683 - f1_score: 0.4654 - loss: 1.4765 - precision: 0.6772 - recall: 0.2565 - val_accuracy: 0.4930 - val_f1_score: 0.4685 - val_loss: 1.3937 - val_precision: 0.7019 - val_recall: 0.2920\n",
      "Epoch 15/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 96ms/step - accuracy: 0.4697 - f1_score: 0.4658 - loss: 1.4477 - precision: 0.6940 - recall: 0.2682 - val_accuracy: 0.4640 - val_f1_score: 0.4510 - val_loss: 1.4596 - val_precision: 0.6941 - val_recall: 0.3040\n",
      "\n",
      "Resultados en TEST:\n",
      "Loss: 1.8236\n",
      "Accuracy: 0.3430\n",
      "Precision: 0.5154\n",
      "Recall: 0.2056\n",
      "F1-score: 0.3271\n"
     ]
    }
   ],
   "source": [
    "hist_vanilla, loss_vanilla, acc_vanilla, prec_vanilla, rec_vanilla, f1_vanilla = entrenar(\n",
    "    modelo_base,\n",
    "    conjunto_entrenamiento,\n",
    "    conjunto_validacion,\n",
    "    conjunto_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dbac01-2708-4699-b48f-4a6771c19238",
   "metadata": {
    "id": "63dbac01-2708-4699-b48f-4a6771c19238"
   },
   "source": [
    "#### 3.2) Modelo 2 - Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02146b3e-1c04-4698-b7b5-398fa73cfc60",
   "metadata": {
    "id": "02146b3e-1c04-4698-b7b5-398fa73cfc60"
   },
   "source": [
    "**Notitas**\n",
    "- con dropout 0.5: El rendimiento es una shit. Precisión y recall son casi nulos, indicando que el dropout fue demasiado alto (0.5) o aplicado en capas pequeñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a73bc93-a8c9-48cd-bf9e-282b2e466103",
   "metadata": {
    "id": "9a73bc93-a8c9-48cd-bf9e-282b2e466103"
   },
   "outputs": [],
   "source": [
    "def dropout():\n",
    "    modelo = models.Sequential([\n",
    "        layers.Input(shape=(dimension_entrada,)),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(num_clases, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    modelo.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy', # porcentaje total de aciertos\n",
    "        metrics.Precision(name='precision'),# mide falsos positivos\n",
    "        metrics.Recall(name='recall'),  # mide falsos negativos\n",
    "        metrics.F1Score(name='f1_score', average='macro')  # media F1 por clase\n",
    "    ])\n",
    "\n",
    "    return modelo\n",
    "\n",
    "modelo_dropout = dropout()\n",
    "modelo_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2501f0-9526-49c1-a2fe-d1c33aa1cbc2",
   "metadata": {
    "id": "6a2501f0-9526-49c1-a2fe-d1c33aa1cbc2",
    "outputId": "f2dc3f4c-9533-4728-93e5-39680c2262a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.1410 - f1_score: 0.1267 - loss: 2.1861 - precision: 0.3206 - recall: 0.0105 - val_accuracy: 0.1670 - val_f1_score: 0.0928 - val_loss: 2.0759 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.1375 - f1_score: 0.1253 - loss: 2.1684 - precision: 0.3462 - recall: 0.0090 - val_accuracy: 0.1630 - val_f1_score: 0.0798 - val_loss: 2.0354 - val_precision: 0.3333 - val_recall: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.1468 - f1_score: 0.1251 - loss: 2.1469 - precision: 0.3656 - recall: 0.0085 - val_accuracy: 0.1850 - val_f1_score: 0.1012 - val_loss: 2.0691 - val_precision: 0.7273 - val_recall: 0.0080\n",
      "Epoch 4/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.1500 - f1_score: 0.1121 - loss: 2.1473 - precision: 0.3846 - recall: 0.0100 - val_accuracy: 0.1910 - val_f1_score: 0.0820 - val_loss: 2.0307 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.1503 - f1_score: 0.1296 - loss: 2.1435 - precision: 0.3800 - recall: 0.0047 - val_accuracy: 0.1870 - val_f1_score: 0.0904 - val_loss: 2.0458 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.1525 - f1_score: 0.1336 - loss: 2.1439 - precision: 0.4000 - recall: 0.0040 - val_accuracy: 0.1480 - val_f1_score: 0.0668 - val_loss: 2.1281 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.1500 - f1_score: 0.1267 - loss: 2.1461 - precision: 0.4468 - recall: 0.0052 - val_accuracy: 0.1770 - val_f1_score: 0.0968 - val_loss: 2.0240 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.1560 - f1_score: 0.1440 - loss: 2.1388 - precision: 0.3200 - recall: 0.0020 - val_accuracy: 0.1880 - val_f1_score: 0.0809 - val_loss: 2.0590 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.1493 - f1_score: 0.1359 - loss: 2.1355 - precision: 0.2105 - recall: 0.0010 - val_accuracy: 0.1980 - val_f1_score: 0.1118 - val_loss: 2.0268 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.1535 - f1_score: 0.1471 - loss: 2.1389 - precision: 0.2500 - recall: 0.0018 - val_accuracy: 0.1850 - val_f1_score: 0.0961 - val_loss: 2.0403 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.1460 - f1_score: 0.1408 - loss: 2.1350 - precision: 0.5294 - recall: 0.0045 - val_accuracy: 0.2090 - val_f1_score: 0.0952 - val_loss: 2.0341 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.1555 - f1_score: 0.1394 - loss: 2.1189 - precision: 0.3611 - recall: 0.0065 - val_accuracy: 0.2020 - val_f1_score: 0.0912 - val_loss: 2.0230 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.1577 - f1_score: 0.1367 - loss: 2.1314 - precision: 0.6667 - recall: 0.0010 - val_accuracy: 0.1730 - val_f1_score: 0.0844 - val_loss: 2.0098 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.1580 - f1_score: 0.1385 - loss: 2.1203 - precision: 0.2941 - recall: 0.0012 - val_accuracy: 0.1770 - val_f1_score: 0.0950 - val_loss: 2.0090 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.1612 - f1_score: 0.1431 - loss: 2.1190 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1700 - val_f1_score: 0.1060 - val_loss: 2.0223 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "\n",
      "Resultados en TEST:\n",
      "Loss: 2.0304\n",
      "Accuracy: 0.1805\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-score: 0.1109\n"
     ]
    }
   ],
   "source": [
    "hist_dropout, loss_dropout, acc_dropout, prec_dropout, rec_dropout, f1_dropout = entrenar(\n",
    "    modelo_dropout,\n",
    "    conjunto_entrenamiento,\n",
    "    conjunto_validacion,\n",
    "    conjunto_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1c6e7-bd6c-4ad5-b335-efbd367a6670",
   "metadata": {
    "id": "19c1c6e7-bd6c-4ad5-b335-efbd367a6670"
   },
   "source": [
    "#### 3.3) Modelo 3 - Regularización L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09793227-89b4-44f2-b46a-6ad27dbb33f8",
   "metadata": {
    "id": "09793227-89b4-44f2-b46a-6ad27dbb33f8"
   },
   "outputs": [],
   "source": [
    "def L1():\n",
    "    modelo = models.Sequential([\n",
    "        layers.Input(shape=(dimension_entrada,)),\n",
    "        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l1(1e-4)),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l1(1e-4)),\n",
    "        layers.Dense(num_clases, activation='softmax')\n",
    "    ])\n",
    "    modelo.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy', # porcentaje total de aciertos\n",
    "            metrics.Precision(name='precision'),# mide falsos positivos\n",
    "            metrics.Recall(name='recall'),  # mide falsos negativos\n",
    "            metrics.F1Score(name='f1_score', average='macro')  # media F1 por clase\n",
    "        ])\n",
    "\n",
    "    return modelo\n",
    "\n",
    "modelo_L1 = L1()\n",
    "modelo_L1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8defa9-b593-48e4-b528-2b8e07142469",
   "metadata": {
    "id": "bb8defa9-b593-48e4-b528-2b8e07142469",
    "outputId": "2dc0aa52-f1b0-4165-9a22-0fa6e467e53e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.2855 - f1_score: 0.2828 - loss: 3.5304 - precision: 0.4698 - recall: 0.1110 - val_accuracy: 0.2770 - val_f1_score: 0.2088 - val_loss: 3.4165 - val_precision: 0.5780 - val_recall: 0.1000\n",
      "Epoch 2/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.2815 - f1_score: 0.2773 - loss: 3.3984 - precision: 0.4851 - recall: 0.0935 - val_accuracy: 0.2290 - val_f1_score: 0.1848 - val_loss: 3.4605 - val_precision: 0.3267 - val_recall: 0.0980\n",
      "Epoch 3/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - accuracy: 0.2822 - f1_score: 0.2816 - loss: 3.3298 - precision: 0.5035 - recall: 0.1088 - val_accuracy: 0.2530 - val_f1_score: 0.1866 - val_loss: 3.2667 - val_precision: 0.3799 - val_recall: 0.1250\n",
      "Epoch 4/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.2955 - f1_score: 0.2940 - loss: 3.1494 - precision: 0.5413 - recall: 0.1130 - val_accuracy: 0.3140 - val_f1_score: 0.2721 - val_loss: 3.1538 - val_precision: 0.5685 - val_recall: 0.1410\n",
      "Epoch 5/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 125ms/step - accuracy: 0.2957 - f1_score: 0.2928 - loss: 3.1943 - precision: 0.5072 - recall: 0.1060 - val_accuracy: 0.3180 - val_f1_score: 0.2552 - val_loss: 3.2086 - val_precision: 0.5632 - val_recall: 0.1560\n",
      "Epoch 6/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 125ms/step - accuracy: 0.2918 - f1_score: 0.2875 - loss: 3.2152 - precision: 0.4995 - recall: 0.1175 - val_accuracy: 0.2820 - val_f1_score: 0.2400 - val_loss: 3.4128 - val_precision: 0.3765 - val_recall: 0.1570\n",
      "Epoch 7/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 125ms/step - accuracy: 0.3045 - f1_score: 0.3016 - loss: 3.1292 - precision: 0.5271 - recall: 0.1215 - val_accuracy: 0.3200 - val_f1_score: 0.2574 - val_loss: 3.0958 - val_precision: 0.5818 - val_recall: 0.0960\n",
      "Epoch 8/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.2985 - f1_score: 0.2945 - loss: 3.0716 - precision: 0.5350 - recall: 0.1185 - val_accuracy: 0.2870 - val_f1_score: 0.2426 - val_loss: 3.0328 - val_precision: 0.5000 - val_recall: 0.1420\n",
      "Epoch 9/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.3083 - f1_score: 0.3055 - loss: 3.0173 - precision: 0.5730 - recall: 0.1168 - val_accuracy: 0.3370 - val_f1_score: 0.3239 - val_loss: 2.7434 - val_precision: 0.7518 - val_recall: 0.1060\n",
      "Epoch 10/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.3050 - f1_score: 0.2993 - loss: 2.9922 - precision: 0.5472 - recall: 0.1233 - val_accuracy: 0.3250 - val_f1_score: 0.3034 - val_loss: 2.9723 - val_precision: 0.6118 - val_recall: 0.1040\n",
      "Epoch 11/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.3063 - f1_score: 0.3038 - loss: 2.8932 - precision: 0.5821 - recall: 0.1170 - val_accuracy: 0.3340 - val_f1_score: 0.2640 - val_loss: 2.8277 - val_precision: 0.6054 - val_recall: 0.1350\n",
      "Epoch 12/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.3083 - f1_score: 0.3040 - loss: 2.9913 - precision: 0.5620 - recall: 0.1190 - val_accuracy: 0.3500 - val_f1_score: 0.2852 - val_loss: 2.8740 - val_precision: 0.5625 - val_recall: 0.1350\n",
      "Epoch 13/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.3050 - f1_score: 0.3006 - loss: 2.9214 - precision: 0.5547 - recall: 0.1077 - val_accuracy: 0.2820 - val_f1_score: 0.2114 - val_loss: 3.0742 - val_precision: 0.5357 - val_recall: 0.1200\n",
      "Epoch 14/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 125ms/step - accuracy: 0.3103 - f1_score: 0.3062 - loss: 2.8834 - precision: 0.5651 - recall: 0.1107 - val_accuracy: 0.3440 - val_f1_score: 0.3212 - val_loss: 2.8501 - val_precision: 0.5892 - val_recall: 0.1090\n",
      "Epoch 15/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 122ms/step - accuracy: 0.3327 - f1_score: 0.3270 - loss: 2.7920 - precision: 0.6036 - recall: 0.1245 - val_accuracy: 0.3530 - val_f1_score: 0.3233 - val_loss: 2.4976 - val_precision: 0.6650 - val_recall: 0.1350\n",
      "\n",
      "Resultados en TEST:\n",
      "Loss: 2.6412\n",
      "Accuracy: 0.3114\n",
      "Precision: 0.5911\n",
      "Recall: 0.1066\n",
      "F1-score: 0.2791\n"
     ]
    }
   ],
   "source": [
    "hist_L1, loss_L1, acc_L1, prec_L1, rec_L1, f1_L1 = entrenar(\n",
    "    modelo_L1,\n",
    "    conjunto_entrenamiento,\n",
    "    conjunto_validacion,\n",
    "    conjunto_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f350f-6f8a-44a3-91bc-827f33def495",
   "metadata": {
    "id": "4e1f350f-6f8a-44a3-91bc-827f33def495"
   },
   "source": [
    "#### 3.4) Modelo 4 - Regularización L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e36cb-565d-48e7-a916-2950958c1189",
   "metadata": {
    "id": "f02e36cb-565d-48e7-a916-2950958c1189"
   },
   "outputs": [],
   "source": [
    "def L2():\n",
    "    modelo = models.Sequential([\n",
    "        layers.Input(shape=(dimension_entrada,)),\n",
    "        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "        layers.Dense(num_clases, activation='softmax')\n",
    "    ])\n",
    "    modelo.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy', # porcentaje total de aciertos\n",
    "            metrics.Precision(name='precision'),# mide falsos positivos\n",
    "            metrics.Recall(name='recall'),  # mide falsos negativos\n",
    "            metrics.F1Score(name='f1_score', average='macro')  # media F1 por clase\n",
    "        ])\n",
    "    return modelo\n",
    "\n",
    "modelo_L2 = L2()\n",
    "modelo_L2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ee3f8-09a4-4d17-af30-c9d1dc58ffaa",
   "metadata": {
    "id": "077ee3f8-09a4-4d17-af30-c9d1dc58ffaa",
    "outputId": "3efd41cb-cbbe-4036-a904-d5f2e7f5919d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 121ms/step - accuracy: 0.3537 - f1_score: 0.3507 - loss: 1.8618 - precision: 0.6377 - recall: 0.1285 - val_accuracy: 0.3950 - val_f1_score: 0.3641 - val_loss: 1.7650 - val_precision: 0.7268 - val_recall: 0.1410\n",
      "Epoch 2/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.3708 - f1_score: 0.3641 - loss: 1.8129 - precision: 0.6444 - recall: 0.1450 - val_accuracy: 0.3870 - val_f1_score: 0.3622 - val_loss: 1.7430 - val_precision: 0.6920 - val_recall: 0.1550\n",
      "Epoch 3/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 122ms/step - accuracy: 0.3898 - f1_score: 0.3808 - loss: 1.7607 - precision: 0.6721 - recall: 0.1645 - val_accuracy: 0.4210 - val_f1_score: 0.3906 - val_loss: 1.6554 - val_precision: 0.6932 - val_recall: 0.1740\n",
      "Epoch 4/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.3828 - f1_score: 0.3756 - loss: 1.7465 - precision: 0.6335 - recall: 0.1720 - val_accuracy: 0.3940 - val_f1_score: 0.3631 - val_loss: 1.6988 - val_precision: 0.6827 - val_recall: 0.1850\n",
      "Epoch 5/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 121ms/step - accuracy: 0.3907 - f1_score: 0.3856 - loss: 1.7073 - precision: 0.6501 - recall: 0.1830 - val_accuracy: 0.3890 - val_f1_score: 0.3692 - val_loss: 1.6872 - val_precision: 0.6608 - val_recall: 0.1890\n",
      "Epoch 6/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.3880 - f1_score: 0.3843 - loss: 1.7382 - precision: 0.6508 - recall: 0.1807 - val_accuracy: 0.4200 - val_f1_score: 0.3861 - val_loss: 1.6736 - val_precision: 0.6839 - val_recall: 0.2250\n",
      "Epoch 7/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.4160 - f1_score: 0.4100 - loss: 1.6562 - precision: 0.6624 - recall: 0.2065 - val_accuracy: 0.4260 - val_f1_score: 0.3997 - val_loss: 1.6317 - val_precision: 0.6537 - val_recall: 0.2020\n",
      "Epoch 8/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 121ms/step - accuracy: 0.4182 - f1_score: 0.4145 - loss: 1.6618 - precision: 0.6693 - recall: 0.2090 - val_accuracy: 0.4870 - val_f1_score: 0.4976 - val_loss: 1.5447 - val_precision: 0.7935 - val_recall: 0.1960\n",
      "Epoch 9/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 125ms/step - accuracy: 0.4453 - f1_score: 0.4412 - loss: 1.5864 - precision: 0.7092 - recall: 0.2360 - val_accuracy: 0.4760 - val_f1_score: 0.4591 - val_loss: 1.5181 - val_precision: 0.7893 - val_recall: 0.2360\n",
      "Epoch 10/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - accuracy: 0.4470 - f1_score: 0.4423 - loss: 1.5600 - precision: 0.7046 - recall: 0.2432 - val_accuracy: 0.4730 - val_f1_score: 0.4533 - val_loss: 1.5178 - val_precision: 0.7477 - val_recall: 0.2490\n",
      "Epoch 11/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 125ms/step - accuracy: 0.4490 - f1_score: 0.4453 - loss: 1.5816 - precision: 0.7048 - recall: 0.2400 - val_accuracy: 0.4500 - val_f1_score: 0.4334 - val_loss: 1.5427 - val_precision: 0.6902 - val_recall: 0.2540\n",
      "Epoch 12/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - accuracy: 0.4685 - f1_score: 0.4638 - loss: 1.5201 - precision: 0.7313 - recall: 0.2620 - val_accuracy: 0.4780 - val_f1_score: 0.4880 - val_loss: 1.5083 - val_precision: 0.7797 - val_recall: 0.2300\n",
      "Epoch 13/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.4712 - f1_score: 0.4651 - loss: 1.5288 - precision: 0.7017 - recall: 0.2670 - val_accuracy: 0.5260 - val_f1_score: 0.5118 - val_loss: 1.3862 - val_precision: 0.7967 - val_recall: 0.2900\n",
      "Epoch 14/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 125ms/step - accuracy: 0.5000 - f1_score: 0.4973 - loss: 1.4472 - precision: 0.7265 - recall: 0.2915 - val_accuracy: 0.4630 - val_f1_score: 0.4415 - val_loss: 1.5480 - val_precision: 0.6308 - val_recall: 0.2990\n",
      "Epoch 15/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 122ms/step - accuracy: 0.5008 - f1_score: 0.4961 - loss: 1.4370 - precision: 0.7208 - recall: 0.3052 - val_accuracy: 0.5200 - val_f1_score: 0.5180 - val_loss: 1.3877 - val_precision: 0.7506 - val_recall: 0.3190\n",
      "\n",
      "Resultados en TEST:\n",
      "Loss: 1.8520\n",
      "Accuracy: 0.3805\n",
      "Precision: 0.5648\n",
      "Recall: 0.2276\n",
      "F1-score: 0.3675\n"
     ]
    }
   ],
   "source": [
    "hist_L2, loss_L2, acc_L2, prec_L2, rec_L2, f1_L2 = entrenar(\n",
    "    modelo_L2,\n",
    "    conjunto_entrenamiento,\n",
    "    conjunto_validacion,\n",
    "    conjunto_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0147db43-5ffa-42c4-a953-5a1940b1aef9",
   "metadata": {
    "id": "0147db43-5ffa-42c4-a953-5a1940b1aef9"
   },
   "source": [
    "#### 3.5) Modelo 5 - BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c2339-6f44-4fcb-80cb-cb64e49e3e0f",
   "metadata": {
    "id": "450c2339-6f44-4fcb-80cb-cb64e49e3e0f"
   },
   "outputs": [],
   "source": [
    "def batchnorm():\n",
    "    modelo = models.Sequential([\n",
    "        layers.Input(shape=(dimension_entrada,)),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(num_clases, activation='softmax')\n",
    "    ])\n",
    "    modelo.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy', # porcentaje total de aciertos\n",
    "            metrics.Precision(name='precision'),# mide falsos positivos\n",
    "            metrics.Recall(name='recall'),  # mide falsos negativos\n",
    "            metrics.F1Score(name='f1_score', average='macro')  # media F1 por clase\n",
    "        ])\n",
    "    return modelo\n",
    "\n",
    "modelo_bn = batchnorm()\n",
    "modelo_bn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8c531-d607-4fe8-931e-1cb0c6534b3d",
   "metadata": {
    "id": "9fb8c531-d607-4fe8-931e-1cb0c6534b3d",
    "outputId": "39a66f46-e5bc-4d04-9d4e-e065c56cac64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.4735 - f1_score: 0.4708 - loss: 1.4696 - precision: 0.6777 - recall: 0.2603 - val_accuracy: 0.3440 - val_f1_score: 0.3258 - val_loss: 2.0071 - val_precision: 0.4642 - val_recall: 0.2400\n",
      "Epoch 2/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 98ms/step - accuracy: 0.5130 - f1_score: 0.5109 - loss: 1.4108 - precision: 0.7031 - recall: 0.2907 - val_accuracy: 0.3720 - val_f1_score: 0.3359 - val_loss: 1.9003 - val_precision: 0.4619 - val_recall: 0.2850\n",
      "Epoch 3/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 97ms/step - accuracy: 0.5357 - f1_score: 0.5326 - loss: 1.3234 - precision: 0.7184 - recall: 0.3322 - val_accuracy: 0.3140 - val_f1_score: 0.2401 - val_loss: 2.2819 - val_precision: 0.3700 - val_recall: 0.2490\n",
      "Epoch 4/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 99ms/step - accuracy: 0.5683 - f1_score: 0.5643 - loss: 1.2437 - precision: 0.7323 - recall: 0.3898 - val_accuracy: 0.4000 - val_f1_score: 0.3546 - val_loss: 1.8584 - val_precision: 0.5385 - val_recall: 0.2870\n",
      "Epoch 5/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 98ms/step - accuracy: 0.5782 - f1_score: 0.5754 - loss: 1.2026 - precision: 0.7394 - recall: 0.3980 - val_accuracy: 0.4250 - val_f1_score: 0.3652 - val_loss: 1.9736 - val_precision: 0.5337 - val_recall: 0.3480\n",
      "Epoch 6/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 101ms/step - accuracy: 0.5940 - f1_score: 0.5904 - loss: 1.1755 - precision: 0.7326 - recall: 0.4220 - val_accuracy: 0.2890 - val_f1_score: 0.2601 - val_loss: 2.2226 - val_precision: 0.3185 - val_recall: 0.2500\n",
      "Epoch 7/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 100ms/step - accuracy: 0.6150 - f1_score: 0.6128 - loss: 1.1129 - precision: 0.7521 - recall: 0.4453 - val_accuracy: 0.2590 - val_f1_score: 0.2285 - val_loss: 3.0052 - val_precision: 0.2677 - val_recall: 0.2120\n",
      "Epoch 8/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 102ms/step - accuracy: 0.6357 - f1_score: 0.6344 - loss: 1.0631 - precision: 0.7573 - recall: 0.4827 - val_accuracy: 0.3100 - val_f1_score: 0.2655 - val_loss: 2.7659 - val_precision: 0.3361 - val_recall: 0.2820\n",
      "Epoch 9/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 101ms/step - accuracy: 0.6645 - f1_score: 0.6631 - loss: 0.9906 - precision: 0.7772 - recall: 0.5207 - val_accuracy: 0.4450 - val_f1_score: 0.3717 - val_loss: 2.0741 - val_precision: 0.5379 - val_recall: 0.3970\n",
      "Epoch 10/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 102ms/step - accuracy: 0.6915 - f1_score: 0.6898 - loss: 0.9141 - precision: 0.8004 - recall: 0.5663 - val_accuracy: 0.3700 - val_f1_score: 0.3234 - val_loss: 2.5668 - val_precision: 0.3890 - val_recall: 0.3310\n",
      "Epoch 11/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.6808 - f1_score: 0.6809 - loss: 0.9270 - precision: 0.7826 - recall: 0.5608 - val_accuracy: 0.2680 - val_f1_score: 0.2648 - val_loss: 2.7437 - val_precision: 0.2763 - val_recall: 0.2390\n",
      "Epoch 12/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 99ms/step - accuracy: 0.7128 - f1_score: 0.7113 - loss: 0.8701 - precision: 0.8088 - recall: 0.5975 - val_accuracy: 0.2130 - val_f1_score: 0.1466 - val_loss: 5.0939 - val_precision: 0.2144 - val_recall: 0.2020\n",
      "Epoch 13/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 97ms/step - accuracy: 0.7170 - f1_score: 0.7163 - loss: 0.8297 - precision: 0.8064 - recall: 0.6072 - val_accuracy: 0.3710 - val_f1_score: 0.2863 - val_loss: 2.8738 - val_precision: 0.4082 - val_recall: 0.3490\n",
      "Epoch 14/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 96ms/step - accuracy: 0.7475 - f1_score: 0.7472 - loss: 0.7337 - precision: 0.8323 - recall: 0.6590 - val_accuracy: 0.4440 - val_f1_score: 0.3981 - val_loss: 2.1719 - val_precision: 0.4630 - val_recall: 0.4010\n",
      "Epoch 15/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 99ms/step - accuracy: 0.7715 - f1_score: 0.7716 - loss: 0.6928 - precision: 0.8405 - recall: 0.6865 - val_accuracy: 0.2870 - val_f1_score: 0.2696 - val_loss: 3.1226 - val_precision: 0.3001 - val_recall: 0.2740\n",
      "\n",
      "Resultados en TEST:\n",
      "Loss: 5.0098\n",
      "Accuracy: 0.1928\n",
      "Precision: 0.1990\n",
      "Recall: 0.1821\n",
      "F1-score: 0.1477\n"
     ]
    }
   ],
   "source": [
    "hist_bn, loss_bn, acc_bn, prec_bn, rec_bn, f1_bn = entrenar(\n",
    "    modelo_bn,\n",
    "    conjunto_entrenamiento,\n",
    "    conjunto_validacion,\n",
    "    conjunto_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3923c48c-8c52-4597-9661-2804d1639b1f",
   "metadata": {
    "id": "3923c48c-8c52-4597-9661-2804d1639b1f"
   },
   "source": [
    "#### 3.6) Modelo 6 - Híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934be8a9-ab84-4a59-9290-605f17cc861e",
   "metadata": {
    "id": "934be8a9-ab84-4a59-9290-605f17cc861e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5202212c-6417-48fd-9f86-61526b3d9dc7",
   "metadata": {
    "id": "5202212c-6417-48fd-9f86-61526b3d9dc7",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4. Comparación y resumen de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5cc2e-56ed-444e-8384-23512f7a28b5",
   "metadata": {
    "id": "55d5cc2e-56ed-444e-8384-23512f7a28b5",
    "outputId": "4e86edf4-5c68-4851-ad7e-60e6b75c7e0d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Regularización</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2</td>\n",
       "      <td>L2(x)</td>\n",
       "      <td>38.050</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>Ninguna</td>\n",
       "      <td>34.300</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L1</td>\n",
       "      <td>L1(x)</td>\n",
       "      <td>31.137</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BatchNorm</td>\n",
       "      <td>Batch Normalization</td>\n",
       "      <td>19.275</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dropout</td>\n",
       "      <td>Dropout(x)</td>\n",
       "      <td>18.050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Modelo       Regularización  Accuracy  Precision  Recall  F1-Score\n",
       "0        L2                 L2(x)    38.050      0.228   0.228     0.367\n",
       "1    Vanilla              Ninguna    34.300      0.515   0.206     0.327\n",
       "2         L1                L1(x)    31.137      0.591   0.107     0.279\n",
       "3  BatchNorm  Batch Normalization    19.275      0.199   0.182     0.148\n",
       "4    Dropout           Dropout(x)    18.050      0.000   0.000     0.111"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creamos la tabla con los resultados obtenidos\n",
    "# (sustituye los valores entre corchetes por tus variables reales si cambian los nombres)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Modelo\": [\"Vanilla\",\"Dropout\",\"L1\",\"L2 \",\"BatchNorm\"],\n",
    "    \"Regularización\": [\"Ninguna\",\"Dropout(x)\",\"L1(x)\",\"L2(x)\",\"Batch Normalization\"],    # pongo (x) para poner luego los parámetros buenos\n",
    "    \"Accuracy\": [acc_vanilla * 100,acc_dropout * 100,acc_L1 * 100,acc_L2 * 100,acc_bn * 100],\n",
    "    \"Precision\": [prec_vanilla,prec_dropout,prec_L1,rec_L2,prec_bn],\n",
    "    \"Recall\": [rec_vanilla,rec_dropout,rec_L1,rec_L2,rec_bn],\n",
    "    \"F1-Score\": [f1_vanilla,f1_dropout,f1_L1,f1_L2,f1_bn]\n",
    "})\n",
    "\n",
    "results = results.round({\"Accuracy\": 3,\"Precision\": 3,\"Recall\": 3,\"F1-Score\": 3})\n",
    "\n",
    "# Mostramos la tabla ordenada por Accuracy descendente\n",
    "results.sort_values(by=\"Accuracy\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4cdd8d-0bea-44a0-9668-cc6a5ee300fe",
   "metadata": {
    "id": "8c4cdd8d-0bea-44a0-9668-cc6a5ee300fe",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6. Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc99302-ef55-4655-a188-ba4c29c28376",
   "metadata": {
    "id": "3cc99302-ef55-4655-a188-ba4c29c28376"
   },
   "source": [
    "La red neuronal base aprende rápido y obtiene una precisión aceptable en entrenamiento, pero empieza a sobreajustar. Esto se ve porque la accuracy de entrenamiento sigue subiendo mientras que la accuracy de validación deja de mejorar e incluso baja ligeramente. Eso significa que el modelo se está adaptando demasiado a las imágenes concretas del set de entrenamiento y no generaliza tan bien a imágenes nuevas.\n",
    "\n",
    "Cuando añadimos regularización (L2 y Dropout) el entrenamiento es más lento y la accuracy de entrenamiento es un poco más baja, pero la accuracy de validación es más estable y en general más cercana a la de entrenamiento. Esto indica que el modelo es menos dependiente de detalles concretos del conjunto de entrenamiento. En el conjunto de test, que es el que no usamos nunca para ajustar nada, el modelo regularizado mejora ligeramente el resultado respecto al modelo base. Esto sugiere que la regularización ayuda a la red a generalizar mejor.\n",
    "\n",
    "Como desventaja, el modelo regularizado tarda un poco más en converger y necesita más épocas para exprimir su potencial, porque al apagar neuronas (Dropout) y penalizar pesos grandes (L2) le cuesta un poco más “memorizar” patrones. Aun así, para este problema de clasificación de imágenes, es preferible un modelo que generaliza mejor aunque entrene un poco más lento."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AP-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
