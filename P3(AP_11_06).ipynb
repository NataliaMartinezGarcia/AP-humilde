{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3 - Redes Neuronales Residuales "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natalia Martínez García, Lucía Vega Navarrete\n",
    "### Grupo: AP.11.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, metrics, optimizers, losses\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero importamos las librerías que vamos a utilizar a lo largo de la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1234\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijamos una semilla aleatoria para para poder reproducir los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carga y preprocesado del dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Carga "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño total del dataset (ejemplos, columnas): (11000000, 29)\n",
      "División del dataset:\n",
      "Train: (2000000, 28)\n",
      "Test:  (500000, 28)\n",
      "Extra: (8500000, 28)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"HIGGS.csv.gz\") # El archivo está en la misma carpeta que el notebook\n",
    "\n",
    "# Cargar el dataset \n",
    "higgs = pd.read_csv(DATA_PATH, compression=\"gzip\", header=None)\n",
    "\n",
    "print(\"Tamaño total del dataset (ejemplos, columnas):\", higgs.shape)\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = higgs.iloc[:, 1:].to_numpy(dtype=np.float32) # Columnas 1-28: features\n",
    "y = higgs.iloc[:, 0].to_numpy(dtype=np.float32) # Columna 0: label\n",
    "\n",
    "# División como dice el enunciado\n",
    "N_TRAIN = 2000000\n",
    "N_TEST = 500000 \n",
    "\n",
    "# primeros 2 millones para entrenamiento\n",
    "X_train = X[:N_TRAIN]\n",
    "y_train = y[:N_TRAIN]\n",
    "\n",
    "# ultimos 500 000 para test\n",
    "X_test  = X[-N_TEST:]\n",
    "y_test  = y[-N_TEST:]\n",
    "\n",
    "# resto para extra (con esto entrenaremos el modelo con fine tuning)\n",
    "X_extra = X[N_TRAIN:-N_TEST]\n",
    "y_extra = y[N_TRAIN:-N_TEST]\n",
    "\n",
    "print(\"División del dataset:\")\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test:  {X_test.shape}\")\n",
    "print(f\"Extra: {X_extra.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar el **Higgs Boston Dataset**, que contiene 11 millones de ejemplos que tenemos que clasificar como señal (clase 1) o fondo (clase 0). Estas etiquetas corresponden a la primera columna del dataset. Cada ejemplo cuenta con 28 características numéricas cada uno, correspondientes al resto de columnas.\n",
    "\n",
    "Dividimos el dataset en los 3 conjuntos que nos pide el enunciado: los 2 primeros millones de ejemplos para entrenamiento del modelo base, los últimos 500000 para test y los 8.5 millones restantes como conjunto extra para fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aplicar la normalización Z-score a todas las características para ponerlas en el mismo rango. Para ello usamos la fórmula `z = x - media / desviación típica`.\n",
    "\n",
    "Para normalizar los conjuntos, calculamos la media y desviación típica solo del conjunto de train, ya que cualquier información de test no puede influir en el entrenamiento. De lo contrario, estaríamos haciendo *data leakage*, y la red daría resultados artificialmente buenos, pero no reales. Con esa media y desviación típica normalizaremos también extra y test, para que el modelo vea datos en la misma escala en todas las fases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Media train (ya normalizado): -0.00000\n",
      "- Desviación típica train  (ya normalizado): 1.00000\n",
      "\n",
      "DISTRIBUCIÓN DE CLASES:\n",
      "\n",
      "Train:\n",
      "Signal = 1058818 (52.94%)\n",
      "Background = 941182   (47.06%)\n",
      "\n",
      "Extra:\n",
      "Signal = 4505798 (53.01%)\n",
      "Background = 3994202   (46.99%)\n",
      "\n",
      "Test:\n",
      "Signal = 264507 (52.90%)\n",
      "Background = 235493   (47.10%)\n"
     ]
    }
   ],
   "source": [
    "# Normalizar usando solo TRAIN\n",
    "# Media y desviación por columna (feature) \n",
    "\n",
    "\"\"\"\n",
    "Normalizamos usando la media y desviación típica de train porque cualquier info de test no puede influir en el entrenamiento (sería como hacer trampas).\n",
    "Si usamos la media y desviación del test para normalizar, meteríamos información del futuro dentro del entrenamiento y estaríamos haciendo data leakage.\n",
    "Los conjuntos extra y test los normalizamos con la media y std de train porque vamos a entrenar la red con datos normalizados usando esos parámetros.\n",
    "\"\"\"\n",
    "\n",
    "mean_train = X_train.mean(axis=0) # axis = 0 para calcularlo por columnas (cada feature)\n",
    "std_train  = X_train.std(axis=0)\n",
    "\n",
    "# Evitar división por cero en caracteristicas que tengan desviacion tipica 0\n",
    "std_train[std_train == 0] = 1.0\n",
    "\n",
    "# z = (x - media) / desviacion tipica\n",
    "X_train = (X_train - mean_train) / std_train\n",
    "X_extra = (X_extra - mean_train) / std_train # Usamos las mismas media y desviacion que train\n",
    "X_test  = (X_test  - mean_train) / std_train # Usamos las mismas media y desviacion que train\n",
    "\n",
    "print(f\"- Media train (ya normalizado): {X_train.mean():.5f}\")\n",
    "print(f\"- Desviación típica train  (ya normalizado): {X_train.std():.5f}\")\n",
    "\n",
    "# Comprobación del desbalanceo de clases\n",
    "# QUITAMOS ESTO ????????????????\n",
    "def check_balance(name, y):\n",
    "    n = len(y)\n",
    "    n_signal = np.sum(y == 1) # Cuenta ejemplos de clase 1 (señal)\n",
    "    n_back   = np.sum(y == 0) # Cuenta ejemplos de clase 0 (fondo)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Signal = {n_signal} ({100*n_signal/n:.2f}%)\")\n",
    "    print(f\"Background = {n_back}   ({100*n_back/n:.2f}%)\")\n",
    "\n",
    "print(\"\\nDISTRIBUCIÓN DE CLASES:\")\n",
    "check_balance(\"Train\", y_train)\n",
    "check_balance(\"Extra\", y_extra)\n",
    "check_balance(\"Test\",  y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de normalizar, el conjunto de entrenamiento tiene media 0 y desviación típica 1.\n",
    "\n",
    "# QUITAMOS LO DE DESBALANCEO ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creación de red neuronal con capas residuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.models.Model):\n",
    "    # EL BLOQUE TIENE LA MISMA FORMA QUE EL DE LA PRESENTACIÓN DE TEORÍA\n",
    "    def __init__(self, units=128, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units # Num de neuronas en las capas dense\n",
    "        self.dense1 = layers.Dense(units, activation='relu', name=f\"{self.name}_dense1\")\n",
    "        self.dense2 = layers.Dense(units, activation=None, name=f\"{self.name}_dense2\")\n",
    "        self.add = layers.Add(name=f\"{self.name}_add\") # Suma dos matrices\n",
    "        self.activation = layers.Activation('relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Forward pass del bloque\"\"\"\n",
    "        x_skip = x # Guardamos la entrada original para el atajo\n",
    "        out = self.dense1(x)\n",
    "        out = self.dense2(out)\n",
    "        # Capa que suma la entrada original con la salida out\n",
    "        out = self.add([out, x_skip])\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"Necesario para poder guardar y cargar el modelo\"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro bloque residual tiene dos capas densas de 128 neuronas cada una (la capa que pondremos antes del primer bloque transformará las 28 características originales a 128 dimensiones). La primera capa aplica ReLU, la segunda no tiene activación. Después de estas dos capas, sumamos la salida con la entrada original (esto es la conexión residual). Finalmente aplicamos ReLU a esa suma. Esta estructura la hemos tomado de la presentación de teoría.\n",
    "\n",
    "La clase hereda de `keras.Model`y tiene tres métodos:\n",
    "- `__init__` se ejecuta al crear el bloque y define todas las capas. Junto a las que hemos explicado arriba, incluimos una capa Add para hacer la suma. \n",
    "- `get_config` es necesario para que Keras pueda guardar y cargar el modelo (algo que vamos a usar más adelante). Devuelve la configuración del bloque.\n",
    "- `call` es el forward pass, se ejecuta cada vez que pasamos datos por el bloque. Primero guardamos la entrada en `x_skip` para usarla después. Luego procesamos la entrada: pasa por `dense1` (con ReLU), después por `dense2` (sin activación), sumamos esta salida con la entrada original guardada en `x_skip`, y finalmente aplicamos ReLU. El resultado es la salida del bloque. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualNetwork(tf.keras.Model):\n",
    "    \"\"\"Red neuronal entera 2 bloques residuales\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.capa_entrada = layers.Dense(128, activation=\"relu\", name=\"capa_entrada\") # convierte 28 features a 128 dimensiones\n",
    "        self.res_block1 = ResidualBlock(units=128, name=\"res_block1\")\n",
    "        self.res_block2 = ResidualBlock(units=128, name=\"res_block2\")\n",
    "        self.capa_intermedia = layers.Dense(64, activation=\"relu\", name=\"capa_intermedia\")\n",
    "        # 1 neurona con sigmoid para clasificación binaria\n",
    "        # Sigmoid transforma la salida al rango 0-1 que se puede interpretar como probabilidad\n",
    "        self.capa_salida = layers.Dense(1, activation=\"sigmoid\", name=\"capa_salida\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"Forward pass de la red completa\"\"\"\n",
    "        x = self.capa_entrada(inputs)\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.capa_intermedia(x)\n",
    "        outputs = self.capa_salida(x)\n",
    "        return outputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"Necesario para poder guardar y cargar el modelo\"\"\"\n",
    "        return super().get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red tiene:\n",
    "- una capa de entrada de 128 neuronas, que transforma las 28 características originales a 128 dimensiones con activación ReLU\n",
    "- dos bloques residuales (res_block1 y res_block2) con la clase que hemos definido arriba\n",
    "- una capa intermedia de 64 neuronas, reduce la dimensionalidad de 128 a 64 con ReLU para comprimir la información\n",
    "- la capa de salida, que tiene 1 neurona para la clasificación binaria (1 si es señal, 0 si no lo es, y por tanto es fondo). La capa tiene activación sigmoid que produce un valor entre 0 y 1, que podemos interpretar como la probabilidad de que el ejemplo sea señal.\n",
    "\n",
    "Igual que la clase anterior, `ResidualNetwork` hereda de `keras.Model`y define los mismos métodos:\n",
    "- `__init__` define todas las capas de la red al crearla\n",
    "- `call` ejecuta el forward pass: los datos de entrada pasan por la capa de entrada, luego los dos bloques residuales, la capa intermedia y la capa de salida Este método se ejecuta automáticamente cada vez que llamamos al modelo con datos\n",
    "- `get_config` permite guardar el modelo y cargarlo después sin perder la arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"red_residual\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"red_residual\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m3,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CONSTRUIR EL MODELO\n",
    "modelo_base = ResidualNetwork(name=\"red_residual\")\n",
    "# Si usamos clases necesitamos pasar algún dato por el modelo para que construya todas las capas\n",
    "# Para poder ver el summary\n",
    "_ = modelo_base(X_train[:1]) \n",
    "modelo_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementamos el bucle de entrenamiento manualmente, sin usar `.fit()`, siguiendo el tutorial \"Escribir un ciclo de entrenamiento desde cero\" de TensorFlow, proporcionado en el enunciado de esta práctica. Esto nos da control total sobre cada paso del proceso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Preparar los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4096\n",
    "\n",
    "# Convierte arrays de numpy en un dataset de tensorflow\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "# shuffle: Mezcla aleatoriamente los datos\n",
    "# batch: Divide los datos en batches\n",
    "train_dataset = train_dataset.shuffle(buffer_size=100_000, reshuffle_each_iteration=True).batch(BATCH_SIZE)\n",
    "\n",
    "# Dataset de test: solo en batches, sin shuffle\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos los datos siguiendo las indicaciones del tutorial. Dividimos los datos en batches de 4096 para poder tener un entrenamiento que proporcione buenos resultados pero que sea rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Definir loss, optimizador y métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=1e-3) # Optimizador\n",
    "loss_fn = losses.BinaryCrossentropy() # Función de loss (binaria, porque la salida es 0/1)\n",
    "\n",
    "# Métricas para TRAIN\n",
    "train_loss = metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = metrics.BinaryAccuracy(name=\"train_accuracy\")\n",
    "\n",
    "# Métricas para TEST\n",
    "test_loss = metrics.Mean(name=\"test_loss\") # ELIMINARLO ? NO LO PIDE Y NO LO USAMOS\n",
    "test_accuracy = metrics.BinaryAccuracy(name=\"test_accuracy\")\n",
    "# Para calcular F1\n",
    "test_precision = metrics.Precision(name=\"test_precision\")\n",
    "test_recall = metrics.Recall(name=\"test_recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual manera que en el tutorial, definimos las métricas que vamos a usar en training y en test, con la única diferencia de que ampliamos las métricas de test para incluir las que se piden en el enunciado.\n",
    "\n",
    "Usamos el optimizador Adam con learning rate de 0.001, que es un valor estándar que funciona bien en la mayoría de problemas. Adam adapta automáticamente el learning rate para cada parámetro. \n",
    "\n",
    "Como función de loss usamos Binary Crossentropy, ya que nuestro problema es de clasificación binaria. Esta mide la diferencia entre las probabilidades predichas y las etiquetas reales. \n",
    "\n",
    "Definimos métricas separadas para train y test: Mean para la loss (calcula el promedio), BinaryAccuracy para la precisión general, y además Precision y Recall para test que nos permiten calcular a mano el F1-Score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Train step y test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function # Decorador que dice el tutorial que compila la función para más eficiencia\n",
    "def train_step(x, y):\n",
    "    \"\"\"Paso de entrenamiento: forward + loss + backpropagation + actualizar métricas train\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass: obtener predicciones\n",
    "        predictions = modelo_base(x, training=True)\n",
    "        # Calcular loss comparando predicciones con etiquetas reales\n",
    "        loss_value = loss_fn(y, predictions)\n",
    "    grads = tape.gradient(loss_value, modelo_base.trainable_weights) # Calcular gradientes\n",
    "    optimizer.apply_gradients(zip(grads, modelo_base.trainable_weights)) # Actualizar pesos\n",
    "\n",
    "    # Actualizar métricas de entrenamiento\n",
    "    train_loss.update_state(loss_value)\n",
    "    train_accuracy.update_state(y, predictions)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    \"\"\"\n",
    "    Paso de evaluación:\n",
    "      - forward\n",
    "      - actualizar métricas de test (loss, accuracy, precision, recall)\n",
    "    Devuelve las predicciones para poder calcular balanced accuracy fuera\n",
    "    \"\"\"\n",
    "    # Forward pass en modo evaluación (training=False)\n",
    "    predictions = modelo_base(x, training=False)\n",
    "    loss_value = loss_fn(y, predictions)\n",
    "    # Actualizar métricas de test\n",
    "    test_loss.update_state(loss_value)\n",
    "    test_accuracy.update_state(y, predictions)\n",
    "    test_precision.update_state(y, predictions)\n",
    "    test_recall.update_state(y, predictions)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `train_step` ejecuta un paso de entrenamiento para un batch con **base_model**. El decorador `@tf.function` compila la función a un grafo estático de TensorFlow para que sea más eficiente. Dentro de `tf.GradientTape()` hacemos el forward pass llamando al modelo con `training=True` y calculamos el loss. Finalmente, `optimizer.apply_gradients()` actualiza los pesos usando esos gradientes. Al final actualizamos las métricas de entrenamiento con el loss y las predicciones del batch. Hemos omitido el bucle de validación que se incluye en el tutorial ya que no la utilizamos en nuestro problema, al dividir los datos solo en entrenamiento, test y extra.\n",
    "\n",
    "La función `test_step` es similar pero más simple. Hacemos forward pass con `training=False` (modo evaluación), calculamos el loss, y actualizamos las métricas de test (accuracy, precision, recall). No calculamos gradientes ni actualizamos pesos. Devolvemos las predicciones porque luego necesitamos todas juntas para calcular balanced accuracy. Está basada en la función del tutorial utilizada para la validación, pero esta solo la vamos a ejecutar una vez después del entrenamiento en lugar de en acda epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def entrenar_modelo(train_dataset, train_step, train_loss, train_accuracy, epochs=3):\n",
    "    # LE PASAMOS PARAMETROS PORQUE PARA CADA MODELO DISTINTO HAY QUE DEFINIR UN TRAIN_STEP DISTINTO\n",
    "    # ASI QUE LO DEFINIMOS FUERA Y SE LO PASAMOS COMO PARAMETRO\n",
    "    for epoch in range(epochs): # Iterar por cada epoch\n",
    "        print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Iterar sobre los batches del dataset \n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "            loss_value = train_step(x_batch_train, y_batch_train) # paso de entrenamiento\n",
    "\n",
    "            # Mostrar progreso cada 200 batches\n",
    "            if step % 200 == 0:\n",
    "                print(\n",
    "                    \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                    % (step, float(loss_value))\n",
    "                )\n",
    "                print(\"Seen so far: %d samples\" % ((step + 1) * BATCH_SIZE))\n",
    "\n",
    "        # Mostrar las métricas al final de cada epoch \n",
    "        train_acc  = float(train_accuracy.result())\n",
    "        train_loss_epoch = float(train_loss.result())\n",
    "        print(\"\\n--- Training metrics ---\")\n",
    "        print(\"Accuracy: %.4f\" % train_acc)\n",
    "        print(\"Loss: %.4f\" % train_loss_epoch)\n",
    "\n",
    "        # Resetear las métricas al final del epoch\n",
    "        train_loss.reset_state()\n",
    "        train_accuracy.reset_state()\n",
    "        \n",
    "        print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función ejecuta el bucle completo de entrenamiento igual que se hace en el tutorial. Para cada epoch, recorremos todos los batches del dataset. En cada batch llamamos a `train_step`, que hace forward pass, calcula loss, backpropagation y actualiza pesos. Cada 200 batches mostramos el progreso para monitorizar el entrenamiento (como se hace en el tutorial). Al final de cada epoch mostramos las métricas acumuladas (accuracy y loss promedio de todos los batches) y las reseteamos para el siguiente epoch con `.reset_state()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos la red base durante 10 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 0.7083\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.5655\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.5309\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7004\n",
      "Loss: 0.5679\n",
      "Time taken: 7.39s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.5289\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.5310\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.5284\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7348\n",
      "Loss: 0.5236\n",
      "Time taken: 7.62s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.5009\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.5144\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.5047\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7440\n",
      "Loss: 0.5091\n",
      "Time taken: 7.28s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.5094\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4945\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4796\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7497\n",
      "Loss: 0.5006\n",
      "Time taken: 7.15s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.5023\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4961\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4913\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7535\n",
      "Loss: 0.4947\n",
      "Time taken: 7.06s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.4921\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4931\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4745\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7561\n",
      "Loss: 0.4906\n",
      "Time taken: 7.00s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 0.4946\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4849\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4999\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7583\n",
      "Loss: 0.4874\n",
      "Time taken: 9.27s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 0.4935\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4846\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4750\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7601\n",
      "Loss: 0.4849\n",
      "Time taken: 8.70s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 0.4855\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4891\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4983\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7617\n",
      "Loss: 0.4825\n",
      "Time taken: 8.23s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 0.4930\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4815\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4709\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7629\n",
      "Loss: 0.4802\n",
      "Time taken: 8.28s\n"
     ]
    }
   ],
   "source": [
    "entrenar_modelo(train_dataset, train_step, train_loss, train_accuracy, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que al principio el loss baja rápido (de 0.70 a 0.57 solo en el primer epoch) porque el modelo está aprendiendo los patrones básicos desde cero. A partir del segundo, la mejora es más lenta y gradual: el loss sigue bajando poco a poco hasta 0.48 y la accuracy sube del 70% al 76%. Tampoco vemos saltos bruscos ni subidas en el loss, lo que nos indica que el entrenamiento va bien. \n",
    "\n",
    "Sin embargo, no podemos estar seguros de la calidad del entrenamiento hasta que evaluemos la red en el conjunto de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(test_dataset, test_step, test_accuracy, test_precision, test_recall):\n",
    "    \"\"\"Evalúa el modelo en el conjunto de test y calcula todas las métricas\"\"\"\n",
    "    # Listas para acumular predicciones y etiquetas reales y con eso balanced accuracy\n",
    "    y_true_all = [] # Todas las etiquetas reales\n",
    "    y_pred_all = [] # Todas las predicciones binarias\n",
    "    \n",
    "    # Evaluar en todos los batches\n",
    "    for x_batch_test, y_batch_test in test_dataset:\n",
    "        # test_step actualiza loss, accuracy, precision, recall\n",
    "        test_predictions = test_step(x_batch_test, y_batch_test)\n",
    "        \n",
    "        # Guardar para balanced accuracy\n",
    "        y_true_all.append(y_batch_test.numpy().astype(np.int32))\n",
    "        # Convertir probabilidades a clases binarias (umbral=0.5)\n",
    "        y_pred_all.append((test_predictions.numpy() >= 0.5).astype(np.int32))\n",
    "    \n",
    "    # Concatenar todos los batches en un solo array\n",
    "    y_true_all = np.concatenate(y_true_all, axis=0).reshape(-1)\n",
    "    y_pred_all = np.concatenate(y_pred_all, axis=0).reshape(-1)\n",
    "    \n",
    "    # Métricas de test a partir de los objetos de Keras\n",
    "    test_acc = float(test_accuracy.result())\n",
    "    precision = float(test_precision.result())\n",
    "    recall = float(test_recall.result())\n",
    "    f1_score = 2 * precision * recall / (precision + recall + 1e-8) # para que no haya división por 0\n",
    "    \n",
    "    # Balanced Accuracy: calcular accuracy para cada clase y hacer la media\n",
    "    mask_0 = (y_true_all == 0) # pone a True todos los valores de la lista de etiquetas reales que valgan 0\n",
    "    mask_1 = (y_true_all == 1) # pone a True todos los valores de la lista de etiquetas reales que valgan 1\n",
    "    \n",
    "    # Accuracy para cada clase por separado\n",
    "    acc_class0 = np.mean(y_pred_all[mask_0] == y_true_all[mask_0]) # especificidad (verdaderos negativos)\n",
    "    acc_class1 = np.mean(y_pred_all[mask_1] == y_true_all[mask_1]) # sensibilidad (verdaderos positivos)\n",
    "    balanced_accuracy = (acc_class0 + acc_class1) / 2\n",
    "    \n",
    "    # Crear diccionario con resultados\n",
    "    # Lo guardamos porque luego hay que compararlo con el que lleva fine tuning !!!\n",
    "    resultados = {\n",
    "        'accuracy': test_acc,\n",
    "        'balanced_accuracy': balanced_accuracy,\n",
    "        'f1_score': f1_score,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'sensitivity': acc_class1,\n",
    "        'specificity': acc_class0\n",
    "    }\n",
    "    return resultados\n",
    "\n",
    "def mostrar_resultados_test(resultados):\n",
    "    print(\"\\n--- Test metrics ---\")\n",
    "    print(\"Accuracy: %.4f\" % resultados['accuracy'])\n",
    "    print(\"Precision: %.4f\" % resultados['precision'])\n",
    "    print(\"Recall: %.4f\" % resultados['recall'])\n",
    "    print(\"F1-Score: %.4f\" % resultados['f1_score'])\n",
    "    print(\"Balanced Accuracy:\")\n",
    "    print(\"\\tAccuracy Class 0 (background): %.4f\" % resultados['specificity'])\n",
    "    print(\"\\tAccuracy Class 1 (signal): %.4f\" % resultados['sensitivity'])\n",
    "    print(\"\\tMedia: %.4f\" % resultados['balanced_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `evaluar_modelo` procesa todo el conjunto de test en batches. Para cada batch ejecuta `test_step` y guarda las predicciones y etiquetas reales. Al final, calcula todas las métricas: accuracy, precision y recall vienen directamente de las métricas de Keras. El F1-Score lo calculamos a mano con su fórmula. Para balanced accuracy calculamos la accuracy de cada clase por separado: filtramos con máscaras booleanas los ejemplos de clase 0 y clase 1, calculamos cuántos predijimos correctamente en cada clase, y hacemos la media. Esto es importante en datasets desbalanceados porque da el mismo peso a ambas clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test metrics ---\n",
      "Accuracy: 0.7597\n",
      "Precision: 0.7637\n",
      "Recall: 0.7903\n",
      "F1-Score: 0.7768\n",
      "Balanced Accuracy:\n",
      "\tAccuracy Class 0 (background): 0.7254\n",
      "\tAccuracy Class 1 (signal): 0.7903\n",
      "\tMedia: 0.7579\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en test\n",
    "resultados_test = evaluar_modelo(test_dataset,test_step,test_accuracy,test_precision,test_recall)\n",
    "mostrar_resultados_test(resultados_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo alcanza un 75.97% de accuracy en datos que nunca ha visto. Es ligeramente inferior al accuracy final alcanzado en el entrenamiento, pero esto es algo normal y no es señal de overfitting.\n",
    "\n",
    "La precisión del 76% indica que cuando predice señal, acierta aproximadamente 3 de cada 4 veces. El recall (79%) muestra que detecta la gran mayoría de las señales reales. Todo esto se combina al final en un F1-score del 77%, ya que ambas métricas están muy equilibradas.\n",
    "\n",
    "Mirando el balanced accuracy vemos que este es de un 75.79%, muy similar al accuracy normal. Sin embargo, mirando los accuracy de las clases por separado, vemos que el modelo detecta mejor las señales (79%) que los backgrounds (72.5%). Esto pasa porque en el dataset hay ligeramente más ejemplos de señal (53%), como hemos visto cuando analizamos el desbalanceo, y por eso el modelo aprende este patrón. En la práctica esto significa que el modelo tiende a clasificar más eventos como señal. Esto puede estar bien (si queremos asegurarnos de no perder posibles señales) o no (si queremos evitar falsos positivos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo guardado en: residual_network_entrenada.keras\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo entrenado\n",
    "MODEL_PATH = \"residual_network_entrenada.keras\"\n",
    "modelo_base.save(MODEL_PATH)\n",
    "print(f\"\\nModelo guardado en: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Cargar el modelo base ya entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el modelo que entrenamos anteriormente desde el `.keras`. Como definimos clases personalizadas (`ResidualBlock` y `ResidualNetwork`), necesitamos indicarle a Keras cuáles son mediante el parámetro `custom_objects`. Sin esto, Keras no sabría cómo reconstruir nuestros bloques residuales y daría un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado desde: residual_network_entrenada.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"red_residual\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"red_residual\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m3,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_PATH = \"residual_network_entrenada.keras\"\n",
    "# custom_objects para que keras reconozca nuestras clases\n",
    "modelo_finetuning = keras.models.load_model(\n",
    "    MODEL_PATH,\n",
    "    custom_objects={'ResidualBlock': ResidualBlock, 'ResidualNetwork': ResidualNetwork}\n",
    ")\n",
    "\n",
    "print(\"Modelo cargado desde:\", MODEL_PATH)\n",
    "modelo_finetuning.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargado, tenemos el modelo con todos sus pesos ya entrenados, y ahora podemos hacer fine-tuning. Vemos que el summary es exactamente el mismo que la red que construimos al principio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Congelar los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capas del modelo y su estado de entrenamiento:\n",
      "  capa_entrada: trainable=False\n",
      "  res_block1: trainable=False\n",
      "  res_block2: trainable=False\n",
      "  capa_intermedia: trainable=False\n",
      "  capa_salida: trainable=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"red_residual\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"red_residual\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m3,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Congelar todas las capas entrenables del modelo\n",
    "for layer in modelo_finetuning.layers:\n",
    "    layer.trainable = False # Desactivar entrenamiento para esta capa\n",
    "\n",
    "# Comprobamos que están congeladas\n",
    "print(\"Capas del modelo y su estado de entrenamiento:\")\n",
    "for layer in modelo_finetuning.layers:\n",
    "    print(f\"  {layer.name}: trainable={layer.trainable}\")\n",
    "\n",
    "modelo_finetuning.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponemos `trainable=False` en todas las capas del modelo base para que sus pesos no se modifiquen durante el fine-tuning. Esto va a hacer que tengamos muchos menos parámetros que entrenar.\n",
    "\n",
    "Como se ve en el summary, tenemos 0 parámetros entrenables después de congelar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Añadir módulos de adaptación de baja dimensión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapaModeloFineTuning(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    - W: pesos originales (din, dout) - CONGELADOS\n",
    "    - A: matriz (din, r) - ENTRENABLE\n",
    "    - B: matriz (r, dout) - ENTRENABLE\n",
    "    \"\"\"\n",
    "    def __init__(self, capa_original, r=8, alfa=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.r = r\n",
    "        self.alfa = alfa\n",
    "\n",
    "        # Guardamos la activación de la capa original\n",
    "        self.activation = capa_original.activation\n",
    "\n",
    "        # Obtener dimensiones de la capa original\n",
    "        self.din, self.dout = capa_original.kernel.shape\n",
    "\n",
    "        # Pesos base (congelados)\n",
    "        self.W = self.add_weight(\n",
    "            name=f\"{self.name}_W\",\n",
    "            shape=(self.din, self.dout),\n",
    "            initializer=tf.constant_initializer(capa_original.kernel.numpy()), # Copiamos los pesos de la capa original\n",
    "            trainable=False, # No se puede entrenar \n",
    "        )\n",
    "\n",
    "        # bias\n",
    "        self.b = self.add_weight(\n",
    "            name=f\"{self.name}_b\",\n",
    "            shape=(self.dout,),\n",
    "            initializer=tf.constant_initializer(capa_original.bias.numpy()), # Copiamos el bias de la capa original\n",
    "            trainable=False,\n",
    "        )\n",
    "\n",
    "        # matriz A: (din, r)\n",
    "        self.A = self.add_weight(\n",
    "            name=f\"{self.name}_A\",\n",
    "            shape=(self.din, self.r),\n",
    "            initializer=\"glorot_uniform\", # Inicialización estándar\n",
    "            trainable=True, # sí que se entrena\n",
    "        )\n",
    "\n",
    "        # matriz B: (r, dout)\n",
    "        self.B = self.add_weight(\n",
    "            name=f\"{self.name}_B\",\n",
    "            shape=(self.r, self.dout),\n",
    "            initializer=\"zeros\", # Inicializada a cero\n",
    "            trainable=True, # sí que se entrena\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        # Calcular la matriz de ajuste\n",
    "        A_por_B = tf.matmul(self.A, self.B)\n",
    "        pesos_finales = self.W + self.alfa * A_por_B\n",
    "        # salida = x por pesos_finales + bias\n",
    "        out = tf.matmul(x, pesos_finales) + self.b\n",
    "        # Ponemos este if porque en los bloques residuales tenemos algunas sin activación\n",
    "        if self.activation is not None: \n",
    "            out = self.activation(out)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'r': self.r, 'alfa': self.alfa})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos de una capa ya entrenada con pesos W. La idea es adaptar el modelo sin modificar sus pesos originales. En lugar de cambiar directamente los pesos W que ya están entrenados, añadimos un \"ajuste\" pequeño usando dos matrices A y B. \n",
    "\n",
    "La clase `CapaModeloFineTuning` que hemos definido recibe como entrada la capa original ya entrenada y dos hiperparámetros: r (cuanto más pequeño sea más pequeñas van a ser las matrices A y B) y alfa (controla cuánto peso van a tener las matrices en el resultado final).\n",
    "\n",
    "**Inicialización (`__init__`):**\n",
    "\n",
    "Primero extraemos información de la capa original: sus dimensiones (din para entrada, dout para salida) y su función de activación. Luego creamos cuatro conjuntos de pesos:\n",
    "\n",
    "- **W y b (congelados)**: Copiamos los pesos y bias de la capa original y los marcamos como no entrenables (`trainable=False`). Ya están entrenados de antes.\n",
    "\n",
    "- **A (entrenable)**: Matriz de dimensión din x r. Se inicializa con valores aleatorios usando glorot_uniform. Como r es pequeño, esta matriz \"comprime\" la información de entrada.\n",
    "\n",
    "- **B (entrenable)**: Matriz de dimensión r x dout. Se inicializa a ceros para que al principio la adaptación no tenga efecto (la salida inicial es idéntica a la capa original). Esta matriz \"descomprime\" de vuelta a la dimensión de salida.\n",
    "\n",
    "**Forward pass (`call`):**\n",
    "\n",
    "Cuando pasan datos por la capa:\n",
    "1. Multiplicamos las matrices A y B para obtener una matriz din x dout del mismo tamaño que W\n",
    "2. Sumamos esta matriz a W, pero escalada por alfa: `W_final = W + α x (A x B)`\n",
    "3. Aplicamos estos pesos finales a la entrada: `salida = x por W_final + b`\n",
    "4. Si la capa original tenía activación, la aplicamos al resultado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockFineTuning(tf.keras.models.Model):\n",
    "    \n",
    "    def __init__(self, original_block, r=4, alfa=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.r = r\n",
    "        self.alfa = alfa\n",
    "        \n",
    "        # Cambiar las capas Dense del bloque original por la CapaModeloFineTuning\n",
    "        # El resto es lo mismo que el bloque original\n",
    "        self.dense1 = CapaModeloFineTuning(original_block.dense1, r=r, alfa=alfa, name=f\"{self.name}_dense1_ft\")\n",
    "        self.dense2 = CapaModeloFineTuning(original_block.dense2, r=r, alfa=alfa, name=f\"{self.name}_dense2_ft\")\n",
    "        self.add = original_block.add\n",
    "        self.activation = original_block.activation\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Forward pass con conexión residual\"\"\"\n",
    "        # ES IGUAL QUE EL DEL RESIDIAL BLOCK ORIGINAL\n",
    "        x_skip = x\n",
    "        out = self.dense1(x)\n",
    "        out = self.dense2(out)\n",
    "        out = self.add([out, x_skip])\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'r': self.r, 'alfa': self.alfa})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualNetworkFineTuning(tf.keras.Model):\n",
    "    \"\"\"Red residual completa con adaptación de baja dimensión\"\"\"\n",
    "    \n",
    "    def __init__(self, modelo_base, r=4, alfa=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.r = r\n",
    "        self.alfa = alfa\n",
    "        \n",
    "        # Envolver todas las capas Dense con adaptación de baja dimensión\n",
    "        # Cambiar las capas por la CapaModeloFineTuning (o el bloque)\n",
    "        self.capa_entrada = CapaModeloFineTuning(modelo_base.capa_entrada, r=r, alfa=alfa,name=\"ft_capa_entrada\")\n",
    "        self.res_block1 = ResidualBlockFineTuning(modelo_base.res_block1, r=r, alfa=alfa, name=\"ft_res_block1\")\n",
    "        self.res_block2 = ResidualBlockFineTuning(modelo_base.res_block2, r=r, alfa=alfa, name=\"ft_res_block2\")\n",
    "        self.capa_intermedia = CapaModeloFineTuning(modelo_base.capa_intermedia, r=r, alfa=alfa, name=\"ft_capa_intermedia\")\n",
    "        self.capa_salida = CapaModeloFineTuning(modelo_base.capa_salida, r=r, alfa=alfa, name=\"ft_capa_salida\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.capa_entrada(inputs)\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.capa_intermedia(x)\n",
    "        outputs = self.capa_salida(x)\n",
    "        return outputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'r': self.r, 'alfa': self.alfa})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptamos las clases que implementaban el bloque residual y la red completa para poder aplicarles el módulo de adaptación de baja dimensión.\n",
    "\n",
    "- `ResidualBlockFineTuning`: adapta un bloque residual existente para fine-tuning. Recibe el bloque original ya entrenado y los parámetros r y alfa. Reemplazamos las dos capas densas (`dense1` y `dense2`) por versiones con adaptación de baja dimensión usando `CapaModeloFineTuning`. El resto de la arquitectura se mantiene exactamente igual que el bloque original.\n",
    "\n",
    "- `ResidualNetworkFineTuning`: reconstruye toda la arquitectura de la red original pero con adaptación de baja dimensión en todas las capas densas. Recibe el modelo base completo ya entrenado. Envolvemos cada capa/bloque del modelo base con la adaptación (las capas con `CapaModeloFineTuning` y los bloques residuales con`ResidualBlockFineTuning`, que a su vez envuelve sus capas densas internas). Todos usan los mismos valores de r y alfa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"red_residual_fine_tuning\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"red_residual_fine_tuning\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ft_capa_entrada                 │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,336</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapaModeloFineTuning</span>)          │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_res_block1                   │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,072</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlockFineTuning</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_res_block2                   │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,072</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlockFineTuning</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_capa_intermedia              │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapaModeloFineTuning</span>)          │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_capa_salida                  │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapaModeloFineTuning</span>)          │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ft_capa_entrada                 │ ?                      │         \u001b[38;5;34m4,336\u001b[0m │\n",
       "│ (\u001b[38;5;33mCapaModeloFineTuning\u001b[0m)          │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_res_block1                   │ ?                      │        \u001b[38;5;34m35,072\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlockFineTuning\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_res_block2                   │ ?                      │        \u001b[38;5;34m35,072\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlockFineTuning\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_capa_intermedia              │ ?                      │         \u001b[38;5;34m9,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mCapaModeloFineTuning\u001b[0m)          │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_capa_salida                  │ ?                      │           \u001b[38;5;34m325\u001b[0m │\n",
       "│ (\u001b[38;5;33mCapaModeloFineTuning\u001b[0m)          │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,829</span> (327.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,829\u001b[0m (327.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,748</span> (22.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,748\u001b[0m (22.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = 4 # Rango de las matrices A y B (menor = menos parámetros porque son mas pequeñas)\n",
    "alfa = 0.1 # Factor de escala para el ajuste (controla cuánto influye)\n",
    "\n",
    "modelo_ft = ResidualNetworkFineTuning(modelo_finetuning, r=r, alfa=alfa, name=\"red_residual_fine_tuning\")\n",
    "_ = modelo_ft(X_train[:1])\n",
    "modelo_ft.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos elegido r = 4 (mucho menor que las dimensiones originales de las capas) y alfa = 0.1 (para que los ajustes sean sutiles y no cambien drásticamente el comportamiento del modelo original).\n",
    "\n",
    "Ahora, del total de 83,829 parámetros:\n",
    "- **78,081 no entrenables**: Son los pesos originales del modelo base (W y b de todas las capas), que están congelados y no se van a modificar durante el fine-tuning\n",
    "- **5,748 entrenables**: Son las matrices A y B que hemos añadido a cada capa. Estas son las únicas que se entrenarán con los nuevos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Entrenar el modelo adaptado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el conjunto extra en batches igual que hicimos con el conjunto de entrenamiento.\n",
    "\n",
    "Lo importante aquí es que usamos un **learning rate más bajo** (5e-4 en lugar de 1e-3) porque el modelo ya está entrenado y solo queremos hacer ajustes pequeños. Si usáramos un learning rate alto, podríamos estropear el conocimiento ya aprendido en los pesos congelados.\n",
    "\n",
    "Además, definimos métricas, `ft_train_step` y `ft_test_step` de la misma manera que antes, pero específicos para este modelo. De esta manera podemos comparar después los resultados del modelo base con el modelo con fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dataset extra\n",
    "extra_dataset = tf.data.Dataset.from_tensor_slices((X_extra, y_extra))\n",
    "extra_dataset = extra_dataset.shuffle(buffer_size=100_000, reshuffle_each_iteration=True).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir nuevas métricas y optimizador para fine tuning\n",
    "\n",
    "# Optimizador con learning rate MENOR porque queremos ajustes pequeños (la red ya está entrenada)\n",
    "ft_optimizer = optimizers.Adam(learning_rate=5e-4)\n",
    "loss_fn_ft = losses.BinaryCrossentropy()\n",
    "\n",
    "# Crear nuevas métricas para el fine-tuning\n",
    "ft_train_loss = metrics.Mean(name=\"ft_train_loss\")\n",
    "ft_train_accuracy = metrics.BinaryAccuracy(name=\"ft_train_accuracy\")\n",
    "\n",
    "ft_test_accuracy = metrics.BinaryAccuracy(name=\"ft_test_accuracy\")\n",
    "ft_test_precision = metrics.Precision(name=\"ft_test_precision\")\n",
    "ft_test_recall = metrics.Recall(name=\"ft_test_recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def ft_train_step(x, y):\n",
    "    \"\"\"Paso de entrenamiento para fine-tuning\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = modelo_ft(x, training=True)\n",
    "        loss_value = loss_fn_ft(y, predictions)\n",
    "    \n",
    "    # Solo calcula gradientes para variables entrenables (A y B)\n",
    "    grads = tape.gradient(loss_value, modelo_ft.trainable_variables)\n",
    "    ft_optimizer.apply_gradients(zip(grads, modelo_ft.trainable_variables))\n",
    "    \n",
    "    ft_train_loss.update_state(loss_value)\n",
    "    ft_train_accuracy.update_state(y, predictions)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def ft_test_step(x, y):\n",
    "    \"\"\"Paso de evaluación para fine-tuning\"\"\"\n",
    "    predictions = modelo_ft(x, training=False)\n",
    "    \n",
    "    ft_test_accuracy.update_state(y, predictions)\n",
    "    ft_test_precision.update_state(y, predictions)\n",
    "    ft_test_recall.update_state(y, predictions)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos durante 3 epochs con el conjunto extra porque estamos haciendo ajustes finos sobre un modelo ya entrenado, no entrenando desde cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 0.4936\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4923\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4761\n",
      "Seen so far: 1642496 samples\n",
      "Training loss (for one batch) at step 600: 0.4829\n",
      "Seen so far: 2461696 samples\n",
      "Training loss (for one batch) at step 800: 0.4842\n",
      "Seen so far: 3280896 samples\n",
      "Training loss (for one batch) at step 1000: 0.4853\n",
      "Seen so far: 4100096 samples\n",
      "Training loss (for one batch) at step 1200: 0.4760\n",
      "Seen so far: 4919296 samples\n",
      "Training loss (for one batch) at step 1400: 0.4775\n",
      "Seen so far: 5738496 samples\n",
      "Training loss (for one batch) at step 1600: 0.4733\n",
      "Seen so far: 6557696 samples\n",
      "Training loss (for one batch) at step 1800: 0.4769\n",
      "Seen so far: 7376896 samples\n",
      "Training loss (for one batch) at step 2000: 0.4740\n",
      "Seen so far: 8196096 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7612\n",
      "Loss: 0.4832\n",
      "Time taken: 37.44s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.4772\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4904\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4886\n",
      "Seen so far: 1642496 samples\n",
      "Training loss (for one batch) at step 600: 0.4752\n",
      "Seen so far: 2461696 samples\n",
      "Training loss (for one batch) at step 800: 0.4865\n",
      "Seen so far: 3280896 samples\n",
      "Training loss (for one batch) at step 1000: 0.4846\n",
      "Seen so far: 4100096 samples\n",
      "Training loss (for one batch) at step 1200: 0.4835\n",
      "Seen so far: 4919296 samples\n",
      "Training loss (for one batch) at step 1400: 0.4876\n",
      "Seen so far: 5738496 samples\n",
      "Training loss (for one batch) at step 1600: 0.4828\n",
      "Seen so far: 6557696 samples\n",
      "Training loss (for one batch) at step 1800: 0.4822\n",
      "Seen so far: 7376896 samples\n",
      "Training loss (for one batch) at step 2000: 0.4850\n",
      "Seen so far: 8196096 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7618\n",
      "Loss: 0.4821\n",
      "Time taken: 35.80s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.4862\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4898\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4837\n",
      "Seen so far: 1642496 samples\n",
      "Training loss (for one batch) at step 600: 0.4716\n",
      "Seen so far: 2461696 samples\n",
      "Training loss (for one batch) at step 800: 0.4783\n",
      "Seen so far: 3280896 samples\n",
      "Training loss (for one batch) at step 1000: 0.4789\n",
      "Seen so far: 4100096 samples\n",
      "Training loss (for one batch) at step 1200: 0.4943\n",
      "Seen so far: 4919296 samples\n",
      "Training loss (for one batch) at step 1400: 0.4884\n",
      "Seen so far: 5738496 samples\n",
      "Training loss (for one batch) at step 1600: 0.4766\n",
      "Seen so far: 6557696 samples\n",
      "Training loss (for one batch) at step 1800: 0.4666\n",
      "Seen so far: 7376896 samples\n",
      "Training loss (for one batch) at step 2000: 0.4851\n",
      "Seen so far: 8196096 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7620\n",
      "Loss: 0.4817\n",
      "Time taken: 34.78s\n"
     ]
    }
   ],
   "source": [
    "entrenar_modelo(extra_dataset, ft_train_step, ft_train_loss, ft_train_accuracy, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El loss se mantiene bastante estable alrededor de 0.48, mejorando ligeramente de 0.4832 a 0.4817. El accuracy mejora muy poco (de 76.12% a 76.2%). Todo esto era esperado, ya que el modelo base ya funcionaba bien y solo estamos refinándolo con pequeños ajustes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Evaluar en test y comparar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test metrics ---\n",
      "Accuracy: 0.7626\n",
      "Precision: 0.7689\n",
      "Recall: 0.7883\n",
      "F1-Score: 0.7785\n",
      "Balanced Accuracy:\n",
      "\tAccuracy Class 0 (background): 0.7339\n",
      "\tAccuracy Class 1 (signal): 0.7883\n",
      "\tMedia: 0.7611\n"
     ]
    }
   ],
   "source": [
    "resultados_test_ft = evaluar_modelo(\n",
    "    test_dataset, \n",
    "    ft_test_step, \n",
    "    ft_test_accuracy, \n",
    "    ft_test_precision, \n",
    "    ft_test_recall\n",
    ")\n",
    "mostrar_resultados_test(resultados_test_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo con fine-tuning alcanza un 76.26% de accuracy, ligeramente mejor que el modelo base. Las mejoras son pequeñas, pero consistentes en todas las métricas excepto recall, que baja de un 79% a 78.83%. Sin embargo, se compensa con una mejora en precision a 77.08%, de forma que el F1-score también sube al 77.85%. El balanced accuracy también pasa de 75.79% a 76.12% (el accuracy de la clase 1 baja ligeramente pero el de la clase 0 sube).\n",
    "\n",
    "Lo importante es que conseguimos estas mejoras entrenando solo 5,748 parámetros. Esto es mucho más eficiente que reentrenar todo el modelo desde cero con los 8.5 millones de ejemplos extra, ya que requiere menos tiempo de entrenamiento y menos memoria pero mantiene todo el conocimiento ya adquirido en el entrenamiento inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARACIÓN DE RESULTADOS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo Base</th>\n",
       "      <th>Modelo Fine Tuning</th>\n",
       "      <th>Diferencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7597</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.7611</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.7768</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.7637</td>\n",
       "      <td>0.7689</td>\n",
       "      <td>0.0051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.7903</td>\n",
       "      <td>0.7883</td>\n",
       "      <td>-0.0021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Modelo Base  Modelo Fine Tuning  Diferencia\n",
       "Accuracy                0.7597              0.7626      0.0029\n",
       "Balanced Accuracy       0.7579              0.7611      0.0032\n",
       "F1-Score                0.7768              0.7785      0.0016\n",
       "Precision               0.7637              0.7689      0.0051\n",
       "Recall                  0.7903              0.7883     -0.0021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"COMPARACIÓN DE RESULTADOS\")\n",
    "comparacion = pd.DataFrame({\n",
    "    'Modelo Base': [\n",
    "        resultados_test['accuracy'],\n",
    "        resultados_test['balanced_accuracy'],\n",
    "        resultados_test['f1_score'],\n",
    "        resultados_test['precision'],\n",
    "        resultados_test['recall']\n",
    "    ],\n",
    "    'Modelo Fine Tuning': [\n",
    "        resultados_test_ft['accuracy'],\n",
    "        resultados_test_ft['balanced_accuracy'],\n",
    "        resultados_test_ft['f1_score'],\n",
    "        resultados_test_ft['precision'],\n",
    "        resultados_test_ft['recall']\n",
    "    ]\n",
    "}, index=['Accuracy', 'Balanced Accuracy', 'F1-Score', 'Precision', 'Recall'])\n",
    "\n",
    "comparacion['Diferencia'] = comparacion['Modelo Fine Tuning'] - comparacion['Modelo Base']\n",
    "\n",
    "display(comparacion.round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6. Compactar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho el fine-tuning, podemos compactar el modelo fusionando la matriz de pesos originales W con las matrices A y B entrenadas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compactar_capa_finetuning(capa_ft, capa_destino):\n",
    "    \"\"\"\n",
    "    Copia a capa_destino los pesos compactados de una CapaModeloFineTuning.\n",
    "    \"\"\"\n",
    "    # Obtener pesos base y matrices\n",
    "    W_base = capa_ft.W.numpy() # din, dout\n",
    "    b_base = capa_ft.b.numpy()\n",
    "    A = capa_ft.A.numpy() # din, r\n",
    "    B = capa_ft.B.numpy() # r, dout\n",
    "\n",
    "    # calcula alfa x A x B\n",
    "    # usamos @ para multiplicar las matrices porque hemos pasado las matrices a numpy\n",
    "    ajuste = capa_ft.alfa * (A @ B) # din, dout\n",
    "    pesos_compactados = W_base + ajuste\n",
    "\n",
    "    # Copiar los pesos compactados a la capa destino\n",
    "    capa_destino.set_weights([pesos_compactados, b_base])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Esta función toma una capa con adaptación de baja dimensión y fusiona todos sus pesos en una capa Dense normal. Lo calculando `W_final = W + alfa x (A x B)` para cada capa. Como A y B ya están entrenadas, podemos combinarlas con W en una única matriz de pesos. \n",
    "\n",
    "Primero extraemos todos los componentes de la capa con fine-tuning: los pesos base W (que estaban congelados), el bias b, y las matrices A y B (que acabamos de entrenar).\n",
    "\n",
    "Luego calculamos el ajuste multiplicando las matrices A y B. Como A tiene dimensión din x r y B tiene dimensión r x dout, su producto A x B da como resultado una matriz de tamaño din x dout, el mismo que W. Multiplicamos este resultado por alfa (0.1 en nuestro caso) para controlar cuanto influirá ese ajuste.\n",
    "\n",
    "Finalmente sumamos W_base + alfa x (A x B) para obtener los pesos compactados. Esta suma fusiona lo que había aprendido la red con el primer entrenamiento (W) con los ajustes específicos que ha hecho el fine-tuning (A x B). Usamos `set_weights()` para copiar estos pesos compactados y el bias a la capa destino, que es una capa Dense normal sin adaptación.\n",
    "\n",
    "Como resultado, tenemos W + alfa x (A x B) en una sola matriz W_final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"red_residual_compacta\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"red_residual_compacta\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m3,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Máxima diferencia absoluta entre modelo_ft y modelo_compacto: 1.1920929e-07\n"
     ]
    }
   ],
   "source": [
    "# Crear una red residual normal\n",
    "modelo_compacto = ResidualNetwork(name=\"red_residual_compacta\")\n",
    "_ = modelo_compacto(X_train[:1])\n",
    "\n",
    "# Compactar cada capa del modelo fine tuning en el modelo normal\n",
    "compactar_capa_finetuning(modelo_ft.capa_entrada, modelo_compacto.capa_entrada)\n",
    "compactar_capa_finetuning(modelo_ft.res_block1.dense1, modelo_compacto.res_block1.dense1)\n",
    "compactar_capa_finetuning(modelo_ft.res_block1.dense2, modelo_compacto.res_block1.dense2)\n",
    "compactar_capa_finetuning(modelo_ft.res_block2.dense1, modelo_compacto.res_block2.dense1)\n",
    "compactar_capa_finetuning(modelo_ft.res_block2.dense2, modelo_compacto.res_block2.dense2)\n",
    "compactar_capa_finetuning(modelo_ft.capa_intermedia, modelo_compacto.capa_intermedia)\n",
    "compactar_capa_finetuning(modelo_ft.capa_salida, modelo_compacto.capa_salida)\n",
    "\n",
    "modelo_compacto.summary()\n",
    "\n",
    "# COMPROBAMOS QUE HACEN LAS MISMAS PREDICCIONES\n",
    "preds_ft = modelo_ft(X_test[:10000], training=False).numpy()\n",
    "preds_compacto = modelo_compacto(X_test[:10000], training=False).numpy()\n",
    "\n",
    "# Calcular la diferencia máxima entre predicciones\n",
    "max_diff = np.max(np.abs(preds_ft - preds_compacto))\n",
    "print(\"Máxima diferencia absoluta entre modelo_ft y modelo_compacto:\", max_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un modelo con la arquitectura original (`ResidualNetwork`) y copiamos en él los pesos compactados de cada capa del modelo fine-tuning. El resultado es un modelo del mismo tamaño que el base, sin las matrices A y B. Ahora tiene exactamente la misma arquitectura y número de parámetros que el modelo base original (78,081), pero con pesos mejorados.\n",
    "\n",
    "Para comprobar que la compactación funciona correctamente, comprobamos que la red con adaptación y la red compactada nos dan las mismas predicciones para el mismo conjunto de datos. Probamos con 10,000 ejemplos del conjunto de test y calculamos la diferencia máxima entre esas predicciones, y como se puede ver es prácticamente 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AP-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
