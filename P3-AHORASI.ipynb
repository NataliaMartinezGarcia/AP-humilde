{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3 - Redes Neuronales Residuales "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natalia Martínez García, Lucía Vega Navarrete\n",
    "### Grupo: AP.11.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, metrics, optimizers, losses\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijamos la semilla para poder reproducir los resultados\n",
    "seed=1234\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carga y preprocesado del dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Carga "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño total del dataset (ejemplos, columnas): (11000000, 29)\n",
      "División del dataset:\n",
      "Train: (2000000, 28)\n",
      "Test:  (500000, 28)\n",
      "Extra: (8500000, 28)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"HIGGS.csv.gz\") # El archivo está en la misma carpeta que el script\n",
    "\n",
    "# Cargar el dataset \n",
    "higgs = pd.read_csv(DATA_PATH, compression=\"gzip\", header=None)\n",
    "\n",
    "print(\"Tamaño total del dataset (ejemplos, columnas):\", higgs.shape)\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = higgs.iloc[:, 1:].to_numpy(dtype=np.float32) # Columnas 1-28: features\n",
    "y = higgs.iloc[:, 0].to_numpy(dtype=np.float32) # Columna 0: label\n",
    "\n",
    "# División como dice el enunciado\n",
    "N_TRAIN = 2000000\n",
    "N_TEST = 500000\n",
    "\n",
    "X_train = X[:N_TRAIN]\n",
    "y_train = y[:N_TRAIN]\n",
    "\n",
    "X_test  = X[-N_TEST:]\n",
    "y_test  = y[-N_TEST:]\n",
    "\n",
    "X_extra = X[N_TRAIN:-N_TEST]\n",
    "y_extra = y[N_TRAIN:-N_TEST]\n",
    "\n",
    "print(\"División del dataset:\")\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test:  {X_test.shape}\")\n",
    "print(f\"Extra: {X_extra.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Media global train (ya normalizado): -0.00000\n",
      "- Std global train  (ya normalizado): 1.00000\n",
      "\n",
      " Distribución de clases:\n",
      "\n",
      "Train:\n",
      "Signal = 1058818 (52.94%)\n",
      "Background = 941182   (47.06%)\n",
      "\n",
      "Extra:\n",
      "Signal = 4505798 (53.01%)\n",
      "Background = 3994202   (46.99%)\n",
      "\n",
      "Test:\n",
      "Signal = 264507 (52.90%)\n",
      "Background = 235493   (47.10%)\n"
     ]
    }
   ],
   "source": [
    "# Normalizar usando solo TRAIN\n",
    "# Media y desviación por columna (feature) \n",
    "# (x - media_train) / std_train\n",
    "\n",
    "\"\"\"\n",
    "Normalizamos solo en train porque cualquier información del test no puede influir en el entrenamiento (el modelo solo puede ver estadísticas del train).\n",
    "Si usamos la media y desviación del test para normalizar, meteríamos información del futuro dentro del entrenamiento.\n",
    "\n",
    "Eso se llama data leakage (filtración de información) y hace que tus resultados no sean realistas.\n",
    "\"\"\"\n",
    "\n",
    "mean_train = X_train.mean(axis=0) # axis = 0 para calcularlo por columnas (cada feature)\n",
    "std_train  = X_train.std(axis=0)\n",
    "\n",
    "# Evitar división por cero\n",
    "std_train[std_train == 0] = 1.0\n",
    "\n",
    "# Aplicar la transformación estándar: (x - media) / sd\n",
    "X_train = (X_train - mean_train) / std_train\n",
    "X_extra = (X_extra - mean_train) / std_train\n",
    "X_test  = (X_test  - mean_train) / std_train\n",
    "\n",
    "print(f\"- Media global train (ya normalizado): {X_train.mean():.5f}\")\n",
    "print(f\"- Std global train  (ya normalizado): {X_train.std():.5f}\")\n",
    "\n",
    "# Comprobación del desbalanceo de clases\n",
    "def class_stats(name, y):\n",
    "    n = len(y)\n",
    "    n_signal = np.sum(y == 1)\n",
    "    n_back   = np.sum(y == 0)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Signal = {n_signal} ({100*n_signal/n:.2f}%)\")\n",
    "    print(f\"Background = {n_back}   ({100*n_back/n:.2f}%)\")\n",
    "\n",
    "print(\"\\n Distribución de clases:\")\n",
    "class_stats(\"Train\", y_train)\n",
    "class_stats(\"Extra\", y_extra)\n",
    "class_stats(\"Test\",  y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creación de red neuronal con capas residuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.models.Model):\n",
    "    \n",
    "    def __init__(self, units=128, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        # Inicializamos las capas en __init__ en lugar de en build\n",
    "        self.dense1 = layers.Dense(units, activation='relu', name=f\"{self.name}_dense1\")\n",
    "        self.dense2 = layers.Dense(units, activation=None, name=f\"{self.name}_dense2\")\n",
    "        self.add = layers.Add(name=f\"{self.name}_add\")\n",
    "        self.activation = layers.Activation('relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Forward pass con conexión residual.\"\"\"\n",
    "        x_skip = x\n",
    "        out = self.dense1(x)\n",
    "        out = self.dense2(out)\n",
    "        out = self.add([out, x_skip])\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualNetwork(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Inicializamos todas las capas en __init__\n",
    "        self.capa_entrada = layers.Dense(128, activation=\"relu\", name=\"capa_entrada\")\n",
    "        self.res_block1 = ResidualBlock(units=128, name=\"res_block1\")\n",
    "        self.res_block2 = ResidualBlock(units=128, name=\"res_block2\")\n",
    "        self.capa_intermedia = layers.Dense(64, activation=\"relu\", name=\"capa_intermedia\")\n",
    "        self.capa_salida = layers.Dense(1, activation=\"sigmoid\", name=\"capa_salida\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"Forward pass de la red completa.\"\"\"\n",
    "        x = self.capa_entrada(inputs)\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.capa_intermedia(x)\n",
    "        outputs = self.capa_salida(x)\n",
    "        return outputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"red_residual\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"red_residual\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m3,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CONSTRUIR EL MODELO\n",
    "modelo_base = ResidualNetwork(name=\"red_residual\")\n",
    "_ = modelo_base(X_train[:1]) # # Para que podamos ver el summary\n",
    "modelo_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Entrenamiento de la red\n",
    "\n",
    "En esta práctica hemos implementado el entrenamiento de la red siguiendo la estructura del tutorial “Escribir un ciclo de entrenamiento desde cero” de TensorFlow, proporcionado en el enunciado de esta práctica.\n",
    "El código hace exactamente los mismos bloques lógicos propuestos en el tutorial, lo único diferente es que o ampliamos un poco para el cálculo de las métricas F1Score y balanced accurcay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 28), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 28), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4096\n",
    "\n",
    "# Convierte arrays de numpy en un objeto tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "# shuffle: Mezcla aleatoriamente los datos\n",
    "# batch: Divide los datos en batches\n",
    "train_dataset = train_dataset.shuffle(buffer_size=100_000, reshuffle_each_iteration=True).batch(BATCH_SIZE)\n",
    "\n",
    "# Dataset de test: solo en batches, sin shuffle\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Definir loss, optimizador y métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=1e-3) # Optimizador\n",
    "loss_fn = losses.BinaryCrossentropy() # Función de loss (binaria, porque la salida es 0/1)\n",
    "\n",
    "# Métricas para TRAIN\n",
    "train_loss = metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = metrics.BinaryAccuracy(name=\"train_accuracy\")\n",
    "\n",
    "# Métricas para TEST\n",
    "test_loss = metrics.Mean(name=\"test_loss\") # ELIMINARLO ? NO LO PIDE Y NO LO USAMOS\n",
    "test_accuracy = metrics.BinaryAccuracy(name=\"test_accuracy\")\n",
    "# Toca calcular el F1 a mano tb xq me estaba dando un error de dimensionalidad por usar la clase q lo hace directo de keras lmao \n",
    "test_precision = metrics.Precision(name=\"test_precision\")\n",
    "test_recall    = metrics.Recall(name=\"test_recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    \"\"\"Paso de entrenamiento: forward + loss + backprop + métricas train.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = modelo_base(x, training=True)\n",
    "        loss_value = loss_fn(y, predictions)\n",
    "    grads = tape.gradient(loss_value, modelo_base.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, modelo_base.trainable_weights))\n",
    "\n",
    "    # Actualizar métricas de entrenamiento\n",
    "    train_loss.update_state(loss_value)\n",
    "    train_accuracy.update_state(y, predictions)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    \"\"\"\n",
    "    Paso de evaluación:\n",
    "      - forward\n",
    "      - actualizar métricas de test (loss, accuracy, precision, recall)\n",
    "    Devuelve las predicciones para poder calcular balanced accuracy fuera.\n",
    "    \"\"\"\n",
    "    predictions = modelo_base(x, training=False)\n",
    "    loss_value = loss_fn(y, predictions)\n",
    "\n",
    "    test_loss.update_state(loss_value)\n",
    "    test_accuracy.update_state(y, predictions)\n",
    "    test_precision.update_state(y, predictions)\n",
    "    test_recall.update_state(y, predictions)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def entrenar_modelo(train_dataset, train_step, train_loss, train_accuracy, epochs=3):\n",
    "    # LE PASAMOS PARAMETROS PORQUE PARA CADA MODELO DISTINTO HAY QUE DEFINIR UN TRAIN_STEP DISTINTO\n",
    "    # ASI QUE LO DEFINIMOS FUERA Y SE LO PASAMOS COMO PARAMETRO\n",
    "    for epoch in range(epochs):\n",
    "        print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Iterar sobre los batches del dataset \n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "            loss_value = train_step(x_batch_train, y_batch_train)\n",
    "\n",
    "            # Log cada N batches \n",
    "            if step % 200 == 0:\n",
    "                print(\n",
    "                    \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                    % (step, float(loss_value))\n",
    "                )\n",
    "                print(\"Seen so far: %d samples\" % ((step + 1) * BATCH_SIZE))\n",
    "\n",
    "        # Mostrar las métricas al final de cada epoch \n",
    "        train_acc  = float(train_accuracy.result())\n",
    "        train_loss_epoch = float(train_loss.result())\n",
    "        print(\"\\n--- Training metrics ---\")\n",
    "        print(\"Accuracy: %.4f\" % train_acc)\n",
    "        print(\"Loss: %.4f\" % train_loss_epoch)\n",
    "\n",
    "        # Resetear las métricas al final del epoch\n",
    "        train_loss.reset_state()\n",
    "        train_accuracy.reset_state()\n",
    "        \n",
    "        print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 0.7083\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.5655\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.5309\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7004\n",
      "Loss: 0.5679\n",
      "Time taken: 6.87s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.5289\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.5310\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.5284\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7348\n",
      "Loss: 0.5236\n",
      "Time taken: 6.54s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.5009\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.5144\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.5047\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7440\n",
      "Loss: 0.5091\n",
      "Time taken: 6.59s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.5094\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4945\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4796\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7497\n",
      "Loss: 0.5006\n",
      "Time taken: 6.51s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.5023\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4961\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4913\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7535\n",
      "Loss: 0.4947\n",
      "Time taken: 6.70s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.4921\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4931\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4745\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7561\n",
      "Loss: 0.4906\n",
      "Time taken: 6.25s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 0.4946\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4849\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4999\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7583\n",
      "Loss: 0.4874\n",
      "Time taken: 6.25s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 0.4935\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4846\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4750\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7601\n",
      "Loss: 0.4849\n",
      "Time taken: 6.39s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 0.4855\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4891\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4983\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7617\n",
      "Loss: 0.4825\n",
      "Time taken: 6.43s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 0.4930\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4815\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4709\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7629\n",
      "Loss: 0.4802\n",
      "Time taken: 6.58s\n"
     ]
    }
   ],
   "source": [
    "entrenar_modelo(train_dataset, train_step, train_loss, train_accuracy, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(test_dataset, test_step, test_accuracy, test_precision, test_recall):\n",
    "    # Variables para calcular Balanced Accuracy\n",
    "    y_true_all = []  # Todas las etiquetas reales\n",
    "    y_pred_all = []  # Todas las predicciones binarias\n",
    "    \n",
    "    # Iterar sobre el dataset de test\n",
    "    for x_batch_test, y_batch_test in test_dataset:\n",
    "        # test_step actualiza loss, accuracy, precision, recall\n",
    "        test_predictions = test_step(x_batch_test, y_batch_test)\n",
    "        \n",
    "        # Guardar para balanced accuracy\n",
    "        y_true_all.append(y_batch_test.numpy().astype(np.int32))\n",
    "        y_pred_all.append((test_predictions.numpy() >= 0.5).astype(np.int32))\n",
    "    \n",
    "    y_true_all = np.concatenate(y_true_all, axis=0).reshape(-1)\n",
    "    y_pred_all = np.concatenate(y_pred_all, axis=0).reshape(-1)\n",
    "    \n",
    "    # Métricas de test a partir de los objetos de Keras\n",
    "    test_acc = float(test_accuracy.result())\n",
    "    precision = float(test_precision.result())\n",
    "    recall = float(test_recall.result())\n",
    "    f1_score = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    \n",
    "    # Balanced Accuracy (a mano)\n",
    "    mask_0 = (y_true_all == 0)  # pone a True todos los valores de la lista de etiquetas reales que valgan 0\n",
    "    mask_1 = (y_true_all == 1)  # pone a True todos los valores de la lista de etiquetas reales que valgan 1\n",
    "    \n",
    "    acc_class0 = np.mean(y_pred_all[mask_0] == y_true_all[mask_0])\n",
    "    acc_class1 = np.mean(y_pred_all[mask_1] == y_true_all[mask_1])\n",
    "    balanced_accuracy = (acc_class0 + acc_class1) / 2\n",
    "    \n",
    "    # Crear diccionario con resultados\n",
    "    # Lo guardamos porque luego hay que compararlo con el que lleva fine tuning !!!\n",
    "    resultados = {\n",
    "        'accuracy': test_acc,\n",
    "        'balanced_accuracy': balanced_accuracy,\n",
    "        'f1_score': f1_score,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'sensitivity': acc_class1,\n",
    "        'specificity': acc_class0\n",
    "    }\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "def mostrar_resultados_test(resultados):\n",
    "    print(\"\\n--- Test metrics ---\")\n",
    "    print(\"Accuracy: %.4f\" % resultados['accuracy'])\n",
    "    print(\"Precision: %.4f\" % resultados['precision'])\n",
    "    print(\"Recall: %.4f\" % resultados['recall'])\n",
    "    print(\"F1-Score: %.4f\" % resultados['f1_score'])\n",
    "    \n",
    "    print(\"\\n--- Balanced Accuracy ---\")\n",
    "    print(\"Class 0 (background): %.4f\" % resultados['specificity'])\n",
    "    print(\"Class 1 (signal): %.4f\" % resultados['sensitivity'])\n",
    "    print(\"Media: %.4f\" % resultados['balanced_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test metrics ---\n",
      "Accuracy: 0.7597\n",
      "Precision: 0.7637\n",
      "Recall: 0.7903\n",
      "F1-Score: 0.7768\n",
      "\n",
      "--- Balanced Accuracy ---\n",
      "Class 0 (background): 0.7254\n",
      "Class 1 (signal): 0.7903\n",
      "Media: 0.7579\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en test\n",
    "resultados_test = evaluar_modelo(test_dataset,test_step,test_accuracy,test_precision,test_recall)\n",
    "mostrar_resultados_test(resultados_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo guardado en: residual_network_entrenada.keras\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo entrenado\n",
    "MODEL_PATH = \"residual_network_entrenada.keras\"\n",
    "modelo_base.save(MODEL_PATH)\n",
    "print(f\"\\nModelo guardado en: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Cargar el modelo base ya entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado desde: residual_network_entrenada.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"red_residual\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"red_residual\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m3,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar el modelo base entrenado\n",
    "MODEL_PATH = \"residual_network_entrenada.keras\"\n",
    "# LE PONEMOS OTRO NOMBRE A LA VARIABLE O DEJAMOS LA MISMA ????\n",
    "modelo_finetuning = keras.models.load_model(\n",
    "    MODEL_PATH,\n",
    "    custom_objects={'ResidualBlock': ResidualBlock, 'ResidualNetwork': ResidualNetwork}\n",
    ")\n",
    "print(\"Modelo cargado desde:\", MODEL_PATH)\n",
    "modelo_finetuning.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Congelar los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capas del modelo y su estado de entrenamiento:\n",
      "  capa_entrada: trainable=False\n",
      "  res_block1: trainable=False\n",
      "  res_block2: trainable=False\n",
      "  capa_intermedia: trainable=False\n",
      "  capa_salida: trainable=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"red_residual\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"red_residual\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ capa_entrada (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m3,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block1 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ res_block2 (\u001b[38;5;33mResidualBlock\u001b[0m)      │ ?                      │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_intermedia (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ capa_salida (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Congelar todas las capas del modelo\n",
    "for layer in modelo_finetuning.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Comprobamos que están congeladas\n",
    "print(\"Capas del modelo y su estado de entrenamiento:\")\n",
    "for layer in modelo_finetuning.layers:\n",
    "    print(f\"  {layer.name}: trainable={layer.trainable}\")\n",
    "\n",
    "modelo_finetuning.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Añadir módulos de adaptación de baja dimensión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapaModeloFineTuning(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Capa Dense con adaptación de baja dimensión.\n",
    "    y = (W + α*B*A)*x + b\n",
    "    donde W está congelado y solo A y B son entrenables.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, capa_original, r=8, alpha=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.capa_original = capa_original\n",
    "        self.r = r  # Rango de la descomposición\n",
    "        self.alpha = alpha  # Factor de escala\n",
    "    \n",
    "        # Obtener dimensiones de la capa original\n",
    "        W = capa_original.weights[0]  # Matriz de pesos\n",
    "        # CORRECCIÓN: W en Keras Dense tiene shape (din, dout), NO (dout, din)\n",
    "        self.din, self.dout = W.shape  # Cambiado el orden!\n",
    "        \n",
    "        # Inicializar matrices A y B\n",
    "        # A: (r, din) - inicializada aleatoriamente\n",
    "        self.A = self.add_weight(\n",
    "            name=f\"{self.name}_A\",\n",
    "            shape=(self.r, self.din),\n",
    "            initializer='glorot_uniform', # MIRAR SI ESTA ES INICIALIZACION ALEATORIA DE VERDAD\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        # B: (dout, r) - inicializada a cero\n",
    "        self.B = self.add_weight(\n",
    "            name=f\"{self.name}_B\",\n",
    "            shape=(self.dout, self.r),\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "    \n",
    "    def call(self, x):\n",
    "        # Salida original con W congelado\n",
    "        y_original = self.capa_original(x)\n",
    "        \n",
    "        # Calcular BA (adaptación de baja dimensión)\n",
    "        # B: (dout, r), A: (r, din) -> BA: (dout, din)\n",
    "        BA = tf.matmul(self.B, self.A)\n",
    "        \n",
    "        # Aplicar BA a x: (dout, din) * (batch, din)^T = (batch, dout)\n",
    "        lora_output = self.alpha * tf.matmul(x, BA, transpose_b=True)\n",
    "        \n",
    "        return y_original + lora_output\n",
    "            \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'r': self.r,\n",
    "            'alpha': self.alpha\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockFineTuning(tf.keras.models.Model):\n",
    "    \n",
    "    def __init__(self, original_block, r=4, alpha=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.original_block = original_block\n",
    "        self.r = r\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Envolver las capas Dense del bloque original con la CapaModeloFineTuning\n",
    "        self.dense1 = CapaModeloFineTuning(original_block.dense1, r=r, alpha=alpha, name=f\"{self.name}_dense1_ft\")\n",
    "        self.dense2 = CapaModeloFineTuning(original_block.dense2, r=r, alpha=alpha, name=f\"{self.name}_dense2_ft\")\n",
    "        self.add = original_block.add\n",
    "        self.activation = original_block.activation\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Forward pass con conexión residual.\"\"\"\n",
    "        x_skip = x\n",
    "        out = self.dense1(x)\n",
    "        out = self.dense2(out)\n",
    "        out = self.add([out, x_skip])\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'r': self.r, 'alpha': self.alpha})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualNetworkFineTuning(tf.keras.Model):\n",
    "    \"\"\"Red residual completa con adaptación de baja dimensión\"\"\"\n",
    "    \n",
    "    def __init__(self, modelo_base, r=4, alpha=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.r = r\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Envolver todas las capas Dense con adaptación de baja dimensión\n",
    "        self.capa_entrada = CapaModeloFineTuning(modelo_base.capa_entrada, r=r, alpha=alpha,name=\"ft_capa_entrada\")\n",
    "        self.res_block1 = ResidualBlockFineTuning(modelo_base.res_block1, r=r, alpha=alpha, name=\"ft_res_block1\")\n",
    "        self.res_block2 = ResidualBlockFineTuning(modelo_base.res_block2, r=r, alpha=alpha, name=\"ft_res_block2\")\n",
    "        self.capa_intermedia = CapaModeloFineTuning(modelo_base.capa_intermedia, r=r, alpha=alpha, name=\"ft_capa_intermedia\")\n",
    "        self.capa_salida = CapaModeloFineTuning(modelo_base.capa_salida, r=r, alpha=alpha, name=\"ft_capa_salida\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.capa_entrada(inputs)\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.capa_intermedia(x)\n",
    "        outputs = self.capa_salida(x)\n",
    "        return outputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'r': self.r, 'alpha': self.alpha})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"red_residual_fine_tuning\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"red_residual_fine_tuning\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ft_capa_entrada                 │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapaModeloFineTuning</span>)          │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_res_block1                   │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlockFineTuning</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_res_block2                   │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlockFineTuning</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_capa_intermedia              │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,328</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapaModeloFineTuning</span>)          │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_capa_salida                  │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,105</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapaModeloFineTuning</span>)          │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ft_capa_entrada                 │ ?                      │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "│ (\u001b[38;5;33mCapaModeloFineTuning\u001b[0m)          │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_res_block1                   │ ?                      │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlockFineTuning\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_res_block2                   │ ?                      │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlockFineTuning\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_capa_intermedia              │ ?                      │        \u001b[38;5;34m11,328\u001b[0m │\n",
       "│ (\u001b[38;5;33mCapaModeloFineTuning\u001b[0m)          │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ft_capa_salida                  │ ?                      │         \u001b[38;5;34m1,105\u001b[0m │\n",
       "│ (\u001b[38;5;33mCapaModeloFineTuning\u001b[0m)          │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,073</span> (394.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,073\u001b[0m (394.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,992</span> (89.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,992\u001b[0m (89.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango r: 16\n",
      "Factor alpha: 0.2\n"
     ]
    }
   ],
   "source": [
    "r = 16  # en lugar de 8\n",
    "alpha = 0.2  # en lugar de 0.1\n",
    "\n",
    "modelo_ft = ResidualNetworkFineTuning(modelo_finetuning, r=r, alpha=alpha, name=\"red_residual_fine_tuning\")\n",
    "\n",
    "# Build del modelo\n",
    "_ = modelo_ft(X_train[:1])\n",
    "modelo_ft.summary()\n",
    "\n",
    "print(f\"Rango r: {r}\")\n",
    "print(f\"Factor alpha: {alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Entrenar el modelo adaptado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dataset extra\n",
    "extra_dataset = tf.data.Dataset.from_tensor_slices((X_extra, y_extra))\n",
    "extra_dataset = extra_dataset.shuffle(buffer_size=100_000, reshuffle_each_iteration=True).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir nuevas métricas y optimizador para fine tuning\n",
    "\n",
    "ft_optimizer = optimizers.Adam(learning_rate=5e-4) # PONER UN LEARNING RATE MENOR\n",
    "loss_fn_ft = losses.BinaryCrossentropy()\n",
    "\n",
    "# Crear nuevas métricas para el fine-tuning\n",
    "ft_train_loss = metrics.Mean(name=\"ft_train_loss\")\n",
    "ft_train_accuracy = metrics.BinaryAccuracy(name=\"ft_train_accuracy\")\n",
    "\n",
    "ft_test_accuracy = metrics.BinaryAccuracy(name=\"ft_test_accuracy\")\n",
    "ft_test_precision = metrics.Precision(name=\"ft_test_precision\")\n",
    "ft_test_recall = metrics.Recall(name=\"ft_test_recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def ft_train_step(x, y):\n",
    "    \"\"\"Paso de entrenamiento para fine-tuning\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = modelo_ft(x, training=True)\n",
    "        loss_value = loss_fn_ft(y, predictions)\n",
    "    \n",
    "    # Solo calcular gradientes para variables entrenables (A y B)\n",
    "    grads = tape.gradient(loss_value, modelo_ft.trainable_variables)\n",
    "    ft_optimizer.apply_gradients(zip(grads, modelo_ft.trainable_variables))\n",
    "    \n",
    "    ft_train_loss.update_state(loss_value)\n",
    "    ft_train_accuracy.update_state(y, predictions)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def ft_test_step(x, y):\n",
    "    \"\"\"Paso de evaluación para fine-tuning\"\"\"\n",
    "    predictions = modelo_ft(x, training=False)\n",
    "    \n",
    "    ft_test_accuracy.update_state(y, predictions)\n",
    "    ft_test_precision.update_state(y, predictions)\n",
    "    ft_test_recall.update_state(y, predictions)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 0.4903\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4793\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4750\n",
      "Seen so far: 1642496 samples\n",
      "Training loss (for one batch) at step 600: 0.4952\n",
      "Seen so far: 2461696 samples\n",
      "Training loss (for one batch) at step 800: 0.4929\n",
      "Seen so far: 3280896 samples\n",
      "Training loss (for one batch) at step 1000: 0.4706\n",
      "Seen so far: 4100096 samples\n",
      "Training loss (for one batch) at step 1200: 0.4773\n",
      "Seen so far: 4919296 samples\n",
      "Training loss (for one batch) at step 1400: 0.4815\n",
      "Seen so far: 5738496 samples\n",
      "Training loss (for one batch) at step 1600: 0.4790\n",
      "Seen so far: 6557696 samples\n",
      "Training loss (for one batch) at step 1800: 0.4723\n",
      "Seen so far: 7376896 samples\n",
      "Training loss (for one batch) at step 2000: 0.4788\n",
      "Seen so far: 8196096 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7616\n",
      "Loss: 0.4826\n",
      "Time taken: 41.40s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.4712\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4860\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4792\n",
      "Seen so far: 1642496 samples\n",
      "Training loss (for one batch) at step 600: 0.4716\n",
      "Seen so far: 2461696 samples\n",
      "Training loss (for one batch) at step 800: 0.4821\n",
      "Seen so far: 3280896 samples\n",
      "Training loss (for one batch) at step 1000: 0.4743\n",
      "Seen so far: 4100096 samples\n",
      "Training loss (for one batch) at step 1200: 0.4907\n",
      "Seen so far: 4919296 samples\n",
      "Training loss (for one batch) at step 1400: 0.4864\n",
      "Seen so far: 5738496 samples\n",
      "Training loss (for one batch) at step 1600: 0.4796\n",
      "Seen so far: 6557696 samples\n",
      "Training loss (for one batch) at step 1800: 0.4813\n",
      "Seen so far: 7376896 samples\n",
      "Training loss (for one batch) at step 2000: 0.4858\n",
      "Seen so far: 8196096 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7622\n",
      "Loss: 0.4815\n",
      "Time taken: 40.09s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.4713\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4759\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4852\n",
      "Seen so far: 1642496 samples\n",
      "Training loss (for one batch) at step 600: 0.4777\n",
      "Seen so far: 2461696 samples\n",
      "Training loss (for one batch) at step 800: 0.4746\n",
      "Seen so far: 3280896 samples\n",
      "Training loss (for one batch) at step 1000: 0.4744\n",
      "Seen so far: 4100096 samples\n",
      "Training loss (for one batch) at step 1200: 0.4719\n",
      "Seen so far: 4919296 samples\n",
      "Training loss (for one batch) at step 1400: 0.4700\n",
      "Seen so far: 5738496 samples\n",
      "Training loss (for one batch) at step 1600: 0.4879\n",
      "Seen so far: 6557696 samples\n",
      "Training loss (for one batch) at step 1800: 0.4735\n",
      "Seen so far: 7376896 samples\n",
      "Training loss (for one batch) at step 2000: 0.4898\n",
      "Seen so far: 8196096 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7627\n",
      "Loss: 0.4809\n",
      "Time taken: 42.24s\n"
     ]
    }
   ],
   "source": [
    "entrenar_modelo(extra_dataset, ft_train_step, ft_train_loss, ft_train_accuracy, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Evaluar en test y comparar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test metrics ---\n",
      "Accuracy: 0.7597\n",
      "Precision: 0.7637\n",
      "Recall: 0.7903\n",
      "F1-Score: 0.7768\n",
      "\n",
      "--- Balanced Accuracy ---\n",
      "Class 0 (background): 0.7365\n",
      "Class 1 (signal): 0.7864\n",
      "Media: 0.7615\n"
     ]
    }
   ],
   "source": [
    "resultados_test_ft = evaluar_modelo(\n",
    "    test_dataset, \n",
    "    ft_test_step, \n",
    "    test_accuracy, \n",
    "    test_precision, \n",
    "    test_recall\n",
    ")\n",
    "mostrar_resultados_test(resultados_test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPARACIÓN DE RESULTADOS\n",
      "============================================================\n",
      "Métrica                   Modelo Base     Modelo LoRA     Diferencia     \n",
      "------------------------------------------------------------\n",
      "accuracy                          0.7597         0.7597        +0.0000\n",
      "balanced_accuracy                 0.7579         0.7615        +0.0036\n",
      "f1_score                          0.7768         0.7768        +0.0000\n",
      "precision                         0.7637         0.7637        +0.0000\n",
      "recall                            0.7903         0.7903        +0.0000\n"
     ]
    }
   ],
   "source": [
    "# Comparación\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARACIÓN DE RESULTADOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Métrica':<25} {'Modelo Base':<15} {'Modelo LoRA':<15} {'Diferencia':<15}\")\n",
    "print(\"-\"*60)\n",
    "for metric in ['accuracy', 'balanced_accuracy', 'f1_score', 'precision', 'recall']:\n",
    "    base_val = resultados_test[metric]\n",
    "    lora_val = resultados_test_ft[metric]\n",
    "    diff = lora_val - base_val\n",
    "    print(f\"{metric:<25} {base_val:>14.4f} {lora_val:>14.4f} {diff:>+14.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo con módulo de adaptación de baja dimensión guardado en: residual_network_lora.keras\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo adaptado\n",
    "MODEL_FT_PATH = \"residual_network_lora.keras\"\n",
    "modelo_ft.save(MODEL_FT_PATH)\n",
    "print(f\"\\nModelo con módulo de adaptación de baja dimensión guardado en: {MODEL_FT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
