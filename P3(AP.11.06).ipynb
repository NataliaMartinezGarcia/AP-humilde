{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b624ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño total del dataset: (11000000, 29)\n",
      "Train: (2000000, 29)\n",
      "Test: (500000, 29)\n",
      "Extra: (8500000, 29)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"C:/Users/NataliaUDC/Downloads/higgs/HIGGS.csv.gz\"\n",
    "\n",
    "# 1. Nombres de columnas: 1 etiqueta + 28 features reales\n",
    "col_names = [\"label\"] + [f\"f{i}\" for i in range(28)]\n",
    "\n",
    "# 2. Cargar el dataset local\n",
    "higgs = pd.read_csv(\n",
    "    DATA_PATH,\n",
    "    compression=\"gzip\" if DATA_PATH.endswith(\".gz\") else None,\n",
    "    header=None,\n",
    "    names=col_names\n",
    ")\n",
    "\n",
    "print(\"Tamaño total del dataset:\", higgs.shape)\n",
    "\n",
    "# 3. División: train inicial, test final, extra intermedio\n",
    "N_TRAIN = 2_000_000\n",
    "N_TEST = 500_000\n",
    "\n",
    "train_df = higgs.iloc[:N_TRAIN]\n",
    "test_df  = higgs.iloc[-N_TEST:]\n",
    "extra_df = higgs.iloc[N_TRAIN:-N_TEST]\n",
    "\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Test:\",  test_df.shape)\n",
    "print(\"Extra:\", extra_df.shape)\n",
    "\n",
    "# 4. Separar features (X) y labels (y)\n",
    "def split_xy(df):\n",
    "    X = df.drop(columns=\"label\").to_numpy(dtype=np.float32)\n",
    "    y = df[\"label\"].to_numpy(dtype=np.float32)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = split_xy(train_df)\n",
    "X_test,  y_test  = split_xy(test_df)\n",
    "X_extra, y_extra = split_xy(extra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37761442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de clases en Train:\n",
      "  Clase 0 → 941182 ejemplos (47.059%)\n",
      "  Clase 1 → 1058818 ejemplos (52.941%)\n",
      "\n",
      "Distribución de clases en Extra:\n",
      "  Clase 0 → 3994202 ejemplos (46.991%)\n",
      "  Clase 1 → 4505798 ejemplos (53.009%)\n",
      "\n",
      "Distribución de clases en Test:\n",
      "  Clase 0 → 235493 ejemplos (47.099%)\n",
      "  Clase 1 → 264507 ejemplos (52.901%)\n"
     ]
    }
   ],
   "source": [
    "# 5. Normalizar / estandarizar \"a mano\" usando solo TRAIN\n",
    "\n",
    "# Media y desviación por columna (feature) calculadas a partir del train\n",
    "mean_train = X_train.mean(axis=0)\n",
    "std_train  = X_train.std(axis=0)\n",
    "\n",
    "# Evitar división por cero\n",
    "std_train[std_train == 0] = 1.0\n",
    "\n",
    "# Aplicar la transformación estándar: (x - media) / sd\n",
    "X_train = (X_train - mean_train) / std_train\n",
    "X_extra = (X_extra - mean_train) / std_train\n",
    "X_test  = (X_test  - mean_train) / std_train\n",
    "\n",
    "# 6. Comprobación del desbalanceo de clases\n",
    "def class_stats(name, y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"\\nDistribución de clases en {name}:\")\n",
    "    for cls, cnt in zip(unique, counts):\n",
    "        print(f\"  Clase {int(cls)} → {cnt} ejemplos ({cnt / len(y):.3%})\")\n",
    "\n",
    "class_stats(\"Train\", y_train)\n",
    "class_stats(\"Extra\", y_extra)\n",
    "class_stats(\"Test\",  y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf682e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CON MÉTODOS DE LIBRERÍA \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('HIGGS.csv.gz', header=None, compression='gzip')\n",
    "\n",
    "print(f\"Dataset: {df.shape[0]} ejemplos, {df.shape[1]} columnas\")\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = df.iloc[:, 1:].values  # Features (columnas 1-28)\n",
    "y = df.iloc[:, 0].values   # Labels (columna 0: 0=background, 1=signal)\n",
    "\n",
    "# División según especificaciones\n",
    "X_train = X[:2000000] # Primeros 2 millones\n",
    "y_train = y[:2000000]\n",
    "\n",
    "X_test = X[-500000:] # Últimos 500 mil\n",
    "y_test = y[-500000:]\n",
    "\n",
    "X_extra = X[2000000:-500000] # resto\n",
    "y_extra = y[2000000:-500000]\n",
    "\n",
    "print(f\"\\nDivisión:\")\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test:  {X_test.shape}\")\n",
    "print(f\"Extra: {X_extra.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f945de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el scaler SOLO con datos de entrenamiento\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplicar la misma transformación a test y extra\n",
    "X_test = scaler.transform(X_test)\n",
    "X_extra = scaler.transform(X_extra)\n",
    "\n",
    "print(\"✓ Normalización completada\")\n",
    "print(f\"  - Media train: {X_train.mean():.6f}\")\n",
    "print(f\"  - Std train: {X_train.std():.6f}\")\n",
    "\n",
    "# Mostrar distribución de clases\n",
    "print(f\"\\n✓ Distribución de clases:\")\n",
    "print(f\"  - Train: Signal={np.sum(y_train==1)} ({100*np.mean(y_train==1):.1f}%), \"\n",
    "      f\"Background={np.sum(y_train==0)} ({100*np.mean(y_train==0):.1f}%)\")\n",
    "print(f\"  - Test:  Signal={np.sum(y_test==1)} ({100*np.mean(y_test==1):.1f}%), \"\n",
    "      f\"Background={np.sum(y_test==0)} ({100*np.mean(y_test==0):.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AP-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
