{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4538d3bd",
   "metadata": {},
   "source": [
    "# Práctica 3 - Redes Neuronales Residuales "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34098200",
   "metadata": {},
   "source": [
    "### Natalia Martínez García, Lucía Vega Navarrete\n",
    "### Grupo: AP.11.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5f3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, metrics, optimizers, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc412d",
   "metadata": {},
   "source": [
    "### 1. Carga y preprocesado del dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1100a3",
   "metadata": {},
   "source": [
    "#### Carga "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b624ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño total del dataset (ejemplos, columnas): (11000000, 29)\n",
      "División del dataset:\n",
      "Train: (2000000, 28)\n",
      "Test:  (500000, 28)\n",
      "Extra: (8500000, 28)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/NataliaUDC/Downloads/higgs/HIGGS.csv.gz\"\n",
    "\n",
    "# Cargar el dataset \n",
    "higgs = pd.read_csv(DATA_PATH, compression=\"gzip\", header=None)\n",
    "\n",
    "print(\"Tamaño total del dataset (ejemplos, columnas):\", higgs.shape)\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "#   - Columna 0: label\n",
    "#   - Columnas 1-28: features\n",
    "X = higgs.iloc[:, 1:].to_numpy(dtype=np.float32) \n",
    "y = higgs.iloc[:, 0].to_numpy(dtype=np.float32)\n",
    "\n",
    "# División según especificaciones: train inicial, test final, extra intermedio\n",
    "N_TRAIN = 2000000\n",
    "N_TEST = 500000\n",
    "\n",
    "X_train = X[:N_TRAIN]\n",
    "y_train = y[:N_TRAIN]\n",
    "\n",
    "X_test  = X[-N_TEST:]\n",
    "y_test  = y[-N_TEST:]\n",
    "\n",
    "X_extra = X[N_TRAIN:-N_TEST]\n",
    "y_extra = y[N_TRAIN:-N_TEST]\n",
    "\n",
    "print(\"División del dataset:\")\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test:  {X_test.shape}\")\n",
    "print(f\"Extra: {X_extra.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e16b2",
   "metadata": {},
   "source": [
    "#### Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37761442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Normalización completada\n",
      "- Media global train (ya normalizado): 0.00000\n",
      "- Std global train  (ya normalizado): 1.00000\n",
      "\n",
      " Distribución de clases:\n",
      "\n",
      "Train:\n",
      "Signal = 1058818 (52.94%)\n",
      "Background = 941182   (47.06%)\n",
      "\n",
      "Extra:\n",
      "Signal = 4505798 (53.01%)\n",
      "Background = 3994202   (46.99%)\n",
      "\n",
      "Test:\n",
      "Signal = 264507 (52.90%)\n",
      "Background = 235493   (47.10%)\n"
     ]
    }
   ],
   "source": [
    "# Normalizar usando solo TRAIN\n",
    "# Media y desviación por columna (feature) \n",
    "#    (x - media_train) / std_train\n",
    "\n",
    "\"\"\"\n",
    "Normalizamos solo en train porque cualquier información del test no puede influir en el entrenamiento (el modelo solo puede ver estadísticas del train).\n",
    "Si usamos la media y desviación del test para normalizar, meteríamos información del futuro dentro del entrenamiento.\n",
    "\n",
    "Eso se llama data leakage (filtración de información) y hace que tus resultados no sean realistas.\n",
    "\"\"\"\n",
    "mean_train = X_train.mean(axis=0) # axis = 0 para calcularlo por columnas (cada feature)\n",
    "std_train  = X_train.std(axis=0)\n",
    "\n",
    "# Evitar división por cero\n",
    "std_train[std_train == 0] = 1.0\n",
    "\n",
    "# Aplicar la transformación estándar: (x - media) / sd\n",
    "X_train = (X_train - mean_train) / std_train\n",
    "X_extra = (X_extra - mean_train) / std_train\n",
    "X_test  = (X_test  - mean_train) / std_train\n",
    "\n",
    "print(\"\\n Normalización completada\")\n",
    "print(f\"- Media global train (ya normalizado): {X_train.mean():.5f}\")\n",
    "print(f\"- Std global train  (ya normalizado): {X_train.std():.5f}\")\n",
    "\n",
    "# Comprobación del desbalanceo de clases\n",
    "def class_stats(name, y):\n",
    "    n = len(y)\n",
    "    n_signal = np.sum(y == 1)\n",
    "    n_back   = np.sum(y == 0)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Signal = {n_signal} ({100*n_signal/n:.2f}%)\")\n",
    "    print(f\"Background = {n_back}   ({100*n_back/n:.2f}%)\")\n",
    "\n",
    "print(\"\\n Distribución de clases:\")\n",
    "class_stats(\"Train\", y_train)\n",
    "class_stats(\"Extra\", y_extra)\n",
    "class_stats(\"Test\",  y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448c6e4b",
   "metadata": {},
   "source": [
    "### 2. Creación de red neuronal con capas residuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0af5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de entrada: 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"higgs_resnet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"higgs_resnet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ higgs_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_in (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> │ higgs_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_dense1   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dense_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_dense2   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ res_block1_dense… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block1_dense… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ dense_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_dense1   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ res_block1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_dense2   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ res_block2_dense… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block2_dense… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ res_block1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_mid (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ res_block2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_mid[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ higgs_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_in (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m3,712\u001b[0m │ higgs_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_dense1   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ dense_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_dense2   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ res_block1_dense… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ res_block1_dense… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │                   │            │ dense_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_dense1   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ res_block1_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_dense2   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ res_block2_dense… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ res_block2_dense… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │                   │            │ res_block1_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_mid (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ res_block2_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_mid[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,081</span> (305.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m78,081\u001b[0m (305.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]  \n",
    "print(\"Tamaño de entrada:\", input_dim)\n",
    "\n",
    "def residual_block(x, units, name):\n",
    "    \"\"\"\n",
    "    Bloque residual con:\n",
    "      - 2 capas lineales (Dense) internas\n",
    "      - 1 conexión residual (skip connection)\n",
    "    \"\"\"\n",
    "    x_skip = x  # conexión residual\n",
    "\n",
    "    # 2 capas lineales antes de hacer la suma residual\n",
    "    x = layers.Dense(units, activation=\"relu\", name=f\"{name}_dense1\")(x)\n",
    "    x = layers.Dense(units, activation=\"relu\", name=f\"{name}_dense2\")(x)\n",
    "\n",
    "    x = layers.Add(name=f\"{name}_add\")([x, x_skip]) # suma residual\n",
    "    return x\n",
    "\n",
    "inputs = keras.Input(shape=(input_dim,), name=\"higgs_input\") \n",
    "x = layers.Dense(128, activation=\"relu\", name=\"dense_in\")(inputs) # Capa de entrada (proyección a dimensión oculta)\n",
    "x = residual_block(x, units=128, name=\"res_block1\") # Bloque residual 1 \n",
    "x = residual_block(x, units=128, name=\"res_block2\") # Bloque residual 2 \n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_mid\")(x) # (Opcional) capa intermedia antes de la salida\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\", name=\"output\")(x) # Capa de salida: 1 neurona con sigmoid para clasificación binaria\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"higgs_resnet\") # Definir el modelo\n",
    "\n",
    "model.summary() # Mostrar resumen para comprobar dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2f6fb",
   "metadata": {},
   "source": [
    "### 3. Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860cb46a",
   "metadata": {},
   "source": [
    "En esta práctica hemos implementado el entrenamiento de la red siguiendo la estructura del tutorial “Escribir un ciclo de entrenamiento desde cero” de TensorFlow, proporcionado en el enunciado de esta práctica.\n",
    "El código hace exactamente los mismos bloques lógicos propuestos en el tutorial, lo único diferente es que o ampliamos un poco para el cálculo de las métricas F1Score y balanced accurcay. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501000f",
   "metadata": {},
   "source": [
    "1. Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd699c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 28), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 28), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4096\n",
    "\n",
    "# Dataset de entrenamiento: barajado + dividido en batches\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=100_000, reshuffle_each_iteration=True).batch(BATCH_SIZE)\n",
    "\n",
    "# Dataset de test: solo en batches, sin shuffle\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "print(train_dataset)\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f89095e",
   "metadata": {},
   "source": [
    "2. Definir loss, optimizer y métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=1e-3) # Optimizador\n",
    "loss_fn = losses.BinaryCrossentropy() # Función de pérdida (binaria, porque es 0/1)\n",
    "\n",
    "\n",
    "# Métricas para TRAIN\n",
    "train_loss = metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = metrics.BinaryAccuracy(name=\"train_accuracy\")\n",
    "\n",
    "# Métricas para TEST\n",
    "test_loss = metrics.Mean(name=\"test_loss\")\n",
    "test_accuracy = metrics.BinaryAccuracy(name=\"test_accuracy\")\n",
    "# Toca calcular el F1 a mano tb xq me estaba dando un error de dimensionalidad por usar la clase q lo hace directo de keras lmao \n",
    "test_precision = metrics.Precision(name=\"test_precision\")\n",
    "test_recall    = metrics.Recall(name=\"test_recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5945b14",
   "metadata": {},
   "source": [
    "3. Esto está copiado tal cual el tutorial, se supone q hace el entrenamiento más rápido \n",
    "\n",
    "`@tf.function` convierte las funciones en grafos de TensorFlow optimizados, lo que hace que el entrenamiento sea más rápido y eficiente.\n",
    "\n",
    "`train_step(x, y)` realiza un paso completo de entrenamiento (forward, cálculo de loss, gradientes, actualización de pesos y de métricas).\n",
    "\n",
    "`test_step(x, y)` realiza la evaluación sobre un batch sin actualizar los pesos, solo actualizando las métricas de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33decfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    \"\"\"Paso de entrenamiento: forward + loss + backprop + métricas train.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x, training=True)\n",
    "        loss_value = loss_fn(y, predictions)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    # Actualizar métricas de entrenamiento\n",
    "    train_loss.update_state(loss_value)\n",
    "    train_accuracy.update_state(y, predictions)\n",
    "    return loss_value\n",
    "    \n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    \"\"\"\n",
    "    Paso de evaluación:\n",
    "      - forward\n",
    "      - actualizar métricas de test (loss, accuracy, precision, recall)\n",
    "    Devuelve las predicciones para poder calcular balanced accuracy fuera.\n",
    "    \"\"\"\n",
    "    predictions = model(x, training=False)\n",
    "    loss_value = loss_fn(y, predictions)\n",
    "\n",
    "    test_loss.update_state(loss_value)\n",
    "    test_accuracy.update_state(y, predictions)\n",
    "    test_precision.update_state(y, predictions)\n",
    "    test_recall.update_state(y, predictions)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ae8d1",
   "metadata": {},
   "source": [
    "4. Bucle de epochs + F1 score + balanced accuracy + guardado "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b352f",
   "metadata": {},
   "source": [
    "La estructura es la misma que el tutorial:\n",
    "* Loop de validación:\n",
    "    * for x_batch_val, y_batch_val in test_ds: val_predictions = test_step(...)\n",
    "* Leer métricas .result().\n",
    "* Resetear métricas (reset_state()).\n",
    "* Imprimir métricas + tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1a08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "START OF EPOCH 1\n",
      "\n",
      "Training loss (for one batch) at step 0: 0.4690\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4703\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4748\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7720\n",
      "Loss: 0.4665\n",
      "\n",
      "--- Validation metrics ---\n",
      "Loss: 0.4802\n",
      "Accuracy: 0.7633\n",
      "Precision: 0.7719\n",
      "Recall: 0.7845\n",
      "F1Score: 0.7781\n",
      "\n",
      "--- Balanced Accuracy ---\n",
      "Class 0 (background): 0.7395\n",
      "Class 1 (signal): 0.7845\n",
      "Media: 0.7620\n",
      "\n",
      "Time taken: 8.02s\n",
      "--------------------------------------------------\n",
      "\n",
      "START OF EPOCH 2\n",
      "\n",
      "Training loss (for one batch) at step 0: 0.4720\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4604\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4506\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7723\n",
      "Loss: 0.4657\n",
      "\n",
      "--- Validation metrics ---\n",
      "Loss: 0.4805\n",
      "Accuracy: 0.7641\n",
      "Precision: 0.7700\n",
      "Recall: 0.7899\n",
      "F1Score: 0.7798\n",
      "\n",
      "--- Balanced Accuracy ---\n",
      "Class 0 (background): 0.7350\n",
      "Class 1 (signal): 0.7899\n",
      "Media: 0.7625\n",
      "\n",
      "Time taken: 8.15s\n",
      "--------------------------------------------------\n",
      "\n",
      "START OF EPOCH 3\n",
      "\n",
      "Training loss (for one batch) at step 0: 0.4775\n",
      "Seen so far: 4096 samples\n",
      "Training loss (for one batch) at step 200: 0.4781\n",
      "Seen so far: 823296 samples\n",
      "Training loss (for one batch) at step 400: 0.4638\n",
      "Seen so far: 1642496 samples\n",
      "\n",
      "--- Training metrics ---\n",
      "Accuracy: 0.7727\n",
      "Loss: 0.4652\n",
      "\n",
      "--- Validation metrics ---\n",
      "Loss: 0.4819\n",
      "Accuracy: 0.7625\n",
      "Precision: 0.7516\n",
      "Recall: 0.8230\n",
      "F1Score: 0.7857\n",
      "\n",
      "--- Balanced Accuracy ---\n",
      "Class 0 (background): 0.6945\n",
      "Class 1 (signal): 0.8230\n",
      "Media: 0.7588\n",
      "\n",
      "Time taken: 8.11s\n",
      "--------------------------------------------------\n",
      "\n",
      "Modelo guardado en: higgs_resnet_trained.keras\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 3 # ajusta según el tiempo que tengas\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"\\nSTART OF EPOCH %d\" % (epoch + 1,))\n",
    "    print(\"\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # FASE DE ENTRENAMIENTO\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "\n",
    "        # Log cada 200 batches \n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * BATCH_SIZE))\n",
    "\n",
    "    # Mostrar las métricas al final de cada epoch \n",
    "    train_acc  = float(train_accuracy.result())\n",
    "    train_loss_epoch = float(train_loss.result())\n",
    "    print(\"\\n--- Training metrics ---\")\n",
    "    print(\"Accuracy: %.4f\" % train_acc)\n",
    "    print(\"Loss: %.4f\" % train_loss_epoch)\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_loss.reset_state()\n",
    "    train_accuracy.reset_state()\n",
    "\n",
    "    # FASE DE EVALUACIÓN (TEST)\n",
    "    # Esto lo usamos luego para el cálculo de balances accuracy \n",
    "    y_true_all = [] # todas las estiquetas reales \n",
    "    y_pred_all = [] # todas las predicciones binarias \n",
    "\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        # test_step actualiza loss, accuracy, precision, recall\n",
    "        val_predictions = test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "        # Guardar para balanced accuracy\n",
    "        y_true_all.append(y_batch_val.numpy().astype(np.int32))\n",
    "        y_pred_all.append((val_predictions.numpy() >= 0.5).astype(np.int32))\n",
    "\n",
    "    y_true_all = np.concatenate(y_true_all, axis=0).reshape(-1)\n",
    "    y_pred_all = np.concatenate(y_pred_all, axis=0).reshape(-1)\n",
    "\n",
    "    # Métricas de test a partir de los objetos de Keras \n",
    "    val_loss = float(test_loss.result())\n",
    "    val_acc = float(test_accuracy.result())\n",
    "    precision = float(test_precision.result())\n",
    "    recall = float(test_recall.result())\n",
    "    f1_score = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\n",
    "    # Reset de métricas de test para la siguiente época\n",
    "    test_loss.reset_state()\n",
    "    test_accuracy.reset_state()\n",
    "    test_precision.reset_state()\n",
    "    test_recall.reset_state()\n",
    "\n",
    "    # Balanced Accuracy (a mano)\n",
    "    # identificamos los índices donde las etiquetas son 0/1\n",
    "    mask_0 = (y_true_all == 0) # pone a True todos los valores de la lista de etiquetas reales que valgan 0\n",
    "    mask_1 = (y_true_all == 1) # pone a True todos los valores de la lista de etiquetas reales que valgan 1\n",
    "\n",
    "    acc_class0 = np.mean(y_pred_all[mask_0] == y_true_all[mask_0])\n",
    "    acc_class1 = np.mean(y_pred_all[mask_1] == y_true_all[mask_1])\n",
    "    balanced_accuracy = (acc_class0 + acc_class1) / 2\n",
    "\n",
    "    # Log de validación como en el tutorial, pero ampliado \n",
    "    print(\"\\n--- Validation metrics ---\")\n",
    "    print(\"Loss: %.4f\" % val_loss)\n",
    "    print(\"Accuracy: %.4f\" % val_acc)\n",
    "    print(\"Precision: %.4f\" % precision)\n",
    "    print(\"Recall: %.4f\" % recall)\n",
    "    print(\"F1Score: %.4f\" % f1_score)\n",
    "\n",
    "    print(\"\\n--- Balanced Accuracy ---\")\n",
    "    print(\"Class 0 (background): %.4f\" % acc_class0)\n",
    "    print(\"Class 1 (signal): %.4f\" % acc_class1)\n",
    "    print(\"Media: %.4f\" % balanced_accuracy)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "    print(\"-\"*50)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "MODEL_PATH = \"higgs_resnet_trained.keras\"\n",
    "model.save(MODEL_PATH)\n",
    "print(f\"\\nModelo guardado en: {MODEL_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AP-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
